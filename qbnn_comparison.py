#!/usr/bin/env python3
"""
QBNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ
======================
è„³å‹æ•£åœ¨æ§‹é€  vs å±¤çŠ¶æ§‹é€  ã®å›å¸°åˆ†ææ¯”è¼ƒ
"""

import torch
import torch.nn as nn
import numpy as np
import time
from typing import Dict, List, Tuple
import warnings
warnings.filterwarnings('ignore')

# è„³å‹QBNNã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from qbnn_brain import QBNNBrainTorch

# ========================================
# å±¤çŠ¶QBNNï¼ˆæ¯”è¼ƒç”¨ã«ç°¡ç•¥åŒ–ï¼‰
# ========================================

class APQB:
    """APQBç†è«–ã®ã‚³ã‚¢"""
    
    @staticmethod
    def theta_to_r(theta):
        return torch.cos(2 * theta)
    
    @staticmethod
    def theta_to_T(theta):
        return torch.abs(torch.sin(2 * theta))


class QBNNLayeredTorch(nn.Module):
    """å±¤çŠ¶QBNNï¼ˆå¾“æ¥å‹ï¼‰"""
    
    def __init__(self, input_size: int, hidden_dims: List[int], output_size: int,
                 entangle_strength: float = 0.5):
        super().__init__()
        
        self.input_size = input_size
        self.output_size = output_size
        self.entangle_strength = nn.Parameter(torch.tensor(entangle_strength))
        
        # å±¤ã‚’æ§‹ç¯‰
        dims = [input_size] + hidden_dims + [output_size]
        
        self.layers = nn.ModuleList()
        self.theta_layers = nn.ModuleList()
        
        # å±¤é–“ã‚‚ã¤ã‚Œãƒ†ãƒ³ã‚½ãƒ«ã‚’å…ˆã«ä½œæˆ
        J_list = [nn.Parameter(torch.zeros(1))]  # æœ€åˆã®å±¤ç”¨ã®ãƒ€ãƒŸãƒ¼
        
        for i in range(len(dims) - 1):
            self.layers.append(nn.Linear(dims[i], dims[i+1]))
            self.theta_layers.append(nn.Linear(dims[i+1], dims[i+1]))
            
            # å±¤é–“ã‚‚ã¤ã‚Œãƒ†ãƒ³ã‚½ãƒ«
            if i > 0:
                J_list.append(nn.Parameter(torch.randn(dims[i], dims[i+1]) * 0.1))
        
        self.J_matrices = nn.ParameterList(J_list)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        h = x
        q_prev = None
        
        for i, (layer, theta_layer) in enumerate(zip(self.layers, self.theta_layers)):
            # ç·šå½¢å¤‰æ›
            h_linear = layer(h)
            
            # Î¸è¨ˆç®—ï¼ˆé‡å­çŠ¶æ…‹ï¼‰
            theta = torch.sigmoid(theta_layer(h_linear)) * np.pi / 2
            r = APQB.theta_to_r(theta)
            
            # ã‚¨ãƒ³ã‚¿ãƒ³ã‚°ãƒ«ãƒ¡ãƒ³ãƒˆè£œæ­£
            if q_prev is not None and i < len(self.J_matrices):
                J = self.J_matrices[i]
                if J.numel() > 1:
                    s_prev = torch.tanh(q_prev)
                    s_curr = torch.tanh(h_linear)
                    
                    # ã‚‚ã¤ã‚Œè£œæ­£
                    entangle = torch.einsum('bi,ij,bj->bj', s_prev, J, s_curr)
                    h_linear = h_linear + self.entangle_strength * entangle
            
            # æ´»æ€§åŒ–ï¼ˆæœ€çµ‚å±¤ä»¥å¤–ï¼‰
            if i < len(self.layers) - 1:
                h = torch.tanh(h_linear)
            else:
                h = h_linear
            
            q_prev = r
        
        return h
    
    def get_quantum_info(self) -> Dict:
        return {
            'entangle_strength': self.entangle_strength.item(),
            'num_layers': len(self.layers),
        }


# ========================================
# æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–¢æ•°
# ========================================

def compare_linear_regression():
    """ç·šå½¢å›å¸°æ¯”è¼ƒ"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ ç·šå½¢å›å¸°æ¯”è¼ƒ: y = 2x + 1")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    X_np = np.linspace(-1, 1, 50).reshape(-1, 1)
    y_np = 2 * X_np + 1 + np.random.randn(50, 1) * 0.1
    
    X = torch.tensor(X_np, dtype=torch.float32)
    y = torch.tensor(y_np, dtype=torch.float32)
    
    results = {}
    
    # ===== è„³å‹QBNN =====
    print("\nğŸ§  è„³å‹æ•£åœ¨æ§‹é€  (QBNN Brain)")
    print("-" * 40)
    
    model_brain = QBNNBrainTorch(
        num_neurons=30,
        input_size=1,
        output_size=1,
        connection_density=0.25
    )
    
    optimizer = torch.optim.Adam(model_brain.parameters(), lr=0.02)
    criterion = nn.MSELoss()
    
    start_time = time.time()
    for epoch in range(150):
        optimizer.zero_grad()
        pred = model_brain(X, time_steps=2)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    brain_time = time.time() - start_time
    
    model_brain.eval()
    with torch.no_grad():
        pred = model_brain(X, time_steps=2)
        brain_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        brain_r2 = 1 - (ss_res / ss_tot)
    
    results['brain'] = {'MSE': brain_mse, 'RÂ²': brain_r2, 'Time': brain_time}
    print(f"   MSE: {brain_mse:.6f}")
    print(f"   RÂ²: {brain_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {brain_time:.2f}ç§’")
    
    # ===== å±¤çŠ¶QBNN =====
    print("\nğŸ“Š å±¤çŠ¶æ§‹é€  (QBNN Layered)")
    print("-" * 40)
    
    model_layered = QBNNLayeredTorch(
        input_size=1,
        hidden_dims=[16, 16],
        output_size=1,
        entangle_strength=0.35
    )
    
    optimizer = torch.optim.Adam(model_layered.parameters(), lr=0.02)
    
    start_time = time.time()
    for epoch in range(150):
        optimizer.zero_grad()
        pred = model_layered(X)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    layered_time = time.time() - start_time
    
    model_layered.eval()
    with torch.no_grad():
        pred = model_layered(X)
        layered_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        layered_r2 = 1 - (ss_res / ss_tot)
    
    results['layered'] = {'MSE': layered_mse, 'RÂ²': layered_r2, 'Time': layered_time}
    print(f"   MSE: {layered_mse:.6f}")
    print(f"   RÂ²: {layered_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {layered_time:.2f}ç§’")
    
    return results


def compare_nonlinear_regression():
    """éç·šå½¢å›å¸°æ¯”è¼ƒ"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ éç·šå½¢å›å¸°æ¯”è¼ƒ: y = sin(Ï€x)")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    X_np = np.linspace(-1, 1, 60).reshape(-1, 1)
    y_np = np.sin(np.pi * X_np) + np.random.randn(60, 1) * 0.05
    
    X = torch.tensor(X_np, dtype=torch.float32)
    y = torch.tensor(y_np, dtype=torch.float32)
    
    results = {}
    criterion = nn.MSELoss()
    
    # ===== è„³å‹QBNN =====
    print("\nğŸ§  è„³å‹æ•£åœ¨æ§‹é€  (QBNN Brain)")
    print("-" * 40)
    
    model_brain = QBNNBrainTorch(
        num_neurons=40,
        input_size=1,
        output_size=1,
        connection_density=0.25
    )
    
    optimizer = torch.optim.Adam(model_brain.parameters(), lr=0.015)
    
    start_time = time.time()
    for epoch in range(200):
        optimizer.zero_grad()
        pred = model_brain(X, time_steps=3)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    brain_time = time.time() - start_time
    
    model_brain.eval()
    with torch.no_grad():
        pred = model_brain(X, time_steps=3)
        brain_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        brain_r2 = 1 - (ss_res / ss_tot)
    
    results['brain'] = {'MSE': brain_mse, 'RÂ²': brain_r2, 'Time': brain_time}
    print(f"   MSE: {brain_mse:.6f}")
    print(f"   RÂ²: {brain_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {brain_time:.2f}ç§’")
    
    # ===== å±¤çŠ¶QBNN =====
    print("\nğŸ“Š å±¤çŠ¶æ§‹é€  (QBNN Layered)")
    print("-" * 40)
    
    model_layered = QBNNLayeredTorch(
        input_size=1,
        hidden_dims=[32, 32],
        output_size=1,
        entangle_strength=0.35
    )
    
    optimizer = torch.optim.Adam(model_layered.parameters(), lr=0.015)
    
    start_time = time.time()
    for epoch in range(200):
        optimizer.zero_grad()
        pred = model_layered(X)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    layered_time = time.time() - start_time
    
    model_layered.eval()
    with torch.no_grad():
        pred = model_layered(X)
        layered_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        layered_r2 = 1 - (ss_res / ss_tot)
    
    results['layered'] = {'MSE': layered_mse, 'RÂ²': layered_r2, 'Time': layered_time}
    print(f"   MSE: {layered_mse:.6f}")
    print(f"   RÂ²: {layered_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {layered_time:.2f}ç§’")
    
    return results


def compare_multivariate_regression():
    """å¤šå¤‰é‡å›å¸°æ¯”è¼ƒ"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ å¤šå¤‰é‡å›å¸°æ¯”è¼ƒ: y = 0.5xâ‚ + 0.3xâ‚‚ - 0.2xâ‚ƒ")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    n_samples = 80
    X_np = np.random.randn(n_samples, 3)
    y_np = (0.5 * X_np[:, 0] + 0.3 * X_np[:, 1] - 0.2 * X_np[:, 2] 
            + np.random.randn(n_samples) * 0.1).reshape(-1, 1)
    
    X = torch.tensor(X_np, dtype=torch.float32)
    y = torch.tensor(y_np, dtype=torch.float32)
    
    results = {}
    criterion = nn.MSELoss()
    
    # ===== è„³å‹QBNN =====
    print("\nğŸ§  è„³å‹æ•£åœ¨æ§‹é€  (QBNN Brain)")
    print("-" * 40)
    
    model_brain = QBNNBrainTorch(
        num_neurons=35,
        input_size=3,
        output_size=1,
        connection_density=0.25
    )
    
    optimizer = torch.optim.Adam(model_brain.parameters(), lr=0.02)
    
    start_time = time.time()
    for epoch in range(150):
        optimizer.zero_grad()
        pred = model_brain(X, time_steps=3)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    brain_time = time.time() - start_time
    
    model_brain.eval()
    with torch.no_grad():
        pred = model_brain(X, time_steps=3)
        brain_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        brain_r2 = 1 - (ss_res / ss_tot)
    
    results['brain'] = {'MSE': brain_mse, 'RÂ²': brain_r2, 'Time': brain_time}
    print(f"   MSE: {brain_mse:.6f}")
    print(f"   RÂ²: {brain_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {brain_time:.2f}ç§’")
    
    # ===== å±¤çŠ¶QBNN =====
    print("\nğŸ“Š å±¤çŠ¶æ§‹é€  (QBNN Layered)")
    print("-" * 40)
    
    model_layered = QBNNLayeredTorch(
        input_size=3,
        hidden_dims=[24, 24],
        output_size=1,
        entangle_strength=0.35
    )
    
    optimizer = torch.optim.Adam(model_layered.parameters(), lr=0.02)
    
    start_time = time.time()
    for epoch in range(150):
        optimizer.zero_grad()
        pred = model_layered(X)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    layered_time = time.time() - start_time
    
    model_layered.eval()
    with torch.no_grad():
        pred = model_layered(X)
        layered_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        layered_r2 = 1 - (ss_res / ss_tot)
    
    results['layered'] = {'MSE': layered_mse, 'RÂ²': layered_r2, 'Time': layered_time}
    print(f"   MSE: {layered_mse:.6f}")
    print(f"   RÂ²: {layered_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {layered_time:.2f}ç§’")
    
    return results


def compare_polynomial_regression():
    """å¤šé …å¼å›å¸°æ¯”è¼ƒ"""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ å¤šé …å¼å›å¸°æ¯”è¼ƒ: y = xÂ³ - xÂ² + 0.5x")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿
    np.random.seed(42)
    X_np = np.linspace(-1, 1, 50).reshape(-1, 1)
    y_np = X_np**3 - X_np**2 + 0.5*X_np + np.random.randn(50, 1) * 0.05
    
    X = torch.tensor(X_np, dtype=torch.float32)
    y = torch.tensor(y_np, dtype=torch.float32)
    
    results = {}
    criterion = nn.MSELoss()
    
    # ===== è„³å‹QBNN =====
    print("\nğŸ§  è„³å‹æ•£åœ¨æ§‹é€  (QBNN Brain)")
    print("-" * 40)
    
    model_brain = QBNNBrainTorch(
        num_neurons=45,
        input_size=1,
        output_size=1,
        connection_density=0.3
    )
    
    optimizer = torch.optim.Adam(model_brain.parameters(), lr=0.015)
    
    start_time = time.time()
    for epoch in range(250):
        optimizer.zero_grad()
        pred = model_brain(X, time_steps=4)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    brain_time = time.time() - start_time
    
    model_brain.eval()
    with torch.no_grad():
        pred = model_brain(X, time_steps=4)
        brain_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        brain_r2 = 1 - (ss_res / ss_tot)
    
    results['brain'] = {'MSE': brain_mse, 'RÂ²': brain_r2, 'Time': brain_time}
    print(f"   MSE: {brain_mse:.6f}")
    print(f"   RÂ²: {brain_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {brain_time:.2f}ç§’")
    
    # ===== å±¤çŠ¶QBNN =====
    print("\nğŸ“Š å±¤çŠ¶æ§‹é€  (QBNN Layered)")
    print("-" * 40)
    
    model_layered = QBNNLayeredTorch(
        input_size=1,
        hidden_dims=[32, 32, 16],
        output_size=1,
        entangle_strength=0.35
    )
    
    optimizer = torch.optim.Adam(model_layered.parameters(), lr=0.015)
    
    start_time = time.time()
    for epoch in range(250):
        optimizer.zero_grad()
        pred = model_layered(X)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    layered_time = time.time() - start_time
    
    model_layered.eval()
    with torch.no_grad():
        pred = model_layered(X)
        layered_mse = criterion(pred, y).item()
        ss_res = ((y - pred) ** 2).sum().item()
        ss_tot = ((y - y.mean()) ** 2).sum().item()
        layered_r2 = 1 - (ss_res / ss_tot)
    
    results['layered'] = {'MSE': layered_mse, 'RÂ²': layered_r2, 'Time': layered_time}
    print(f"   MSE: {layered_mse:.6f}")
    print(f"   RÂ²: {layered_r2:.4f}")
    print(f"   å­¦ç¿’æ™‚é–“: {layered_time:.2f}ç§’")
    
    return results


def compare_classification():
    """åˆ†é¡ã‚¿ã‚¹ã‚¯æ¯”è¼ƒï¼ˆXORï¼‰"""
    print("\n" + "=" * 70)
    print("ğŸ”¢ åˆ†é¡æ¯”è¼ƒ: XORå•é¡Œ")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿
    X = torch.tensor([
        [0, 0],
        [0, 1],
        [1, 0],
        [1, 1],
    ], dtype=torch.float32)
    
    y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)
    
    results = {}
    criterion = nn.MSELoss()
    
    # ===== è„³å‹QBNN =====
    print("\nğŸ§  è„³å‹æ•£åœ¨æ§‹é€  (QBNN Brain)")
    print("-" * 40)
    
    model_brain = QBNNBrainTorch(
        num_neurons=25,
        input_size=2,
        output_size=1,
        connection_density=0.25
    )
    
    optimizer = torch.optim.Adam(model_brain.parameters(), lr=0.03)
    
    start_time = time.time()
    for epoch in range(100):
        optimizer.zero_grad()
        pred = model_brain(X, time_steps=3)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    brain_time = time.time() - start_time
    
    model_brain.eval()
    with torch.no_grad():
        pred = model_brain(X, time_steps=3)
        brain_correct = sum(1 for i in range(4) if (pred[i] > 0.5) == (y[i] > 0.5))
        brain_acc = brain_correct / 4 * 100
    
    results['brain'] = {'Accuracy': brain_acc, 'Time': brain_time}
    print(f"   æ­£è§£ç‡: {brain_acc:.0f}%")
    print(f"   å­¦ç¿’æ™‚é–“: {brain_time:.2f}ç§’")
    
    # ===== å±¤çŠ¶QBNN =====
    print("\nğŸ“Š å±¤çŠ¶æ§‹é€  (QBNN Layered)")
    print("-" * 40)
    
    model_layered = QBNNLayeredTorch(
        input_size=2,
        hidden_dims=[16, 16],
        output_size=1,
        entangle_strength=0.35
    )
    
    optimizer = torch.optim.Adam(model_layered.parameters(), lr=0.03)
    
    start_time = time.time()
    for epoch in range(100):
        optimizer.zero_grad()
        pred = model_layered(X)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
    
    layered_time = time.time() - start_time
    
    model_layered.eval()
    with torch.no_grad():
        pred = model_layered(X)
        layered_correct = sum(1 for i in range(4) if (pred[i] > 0.5) == (y[i] > 0.5))
        layered_acc = layered_correct / 4 * 100
    
    results['layered'] = {'Accuracy': layered_acc, 'Time': layered_time}
    print(f"   æ­£è§£ç‡: {layered_acc:.0f}%")
    print(f"   å­¦ç¿’æ™‚é–“: {layered_time:.2f}ç§’")
    
    return results


def run_full_comparison():
    """å…¨æ¯”è¼ƒã‚’å®Ÿè¡Œ"""
    print("=" * 70)
    print("ğŸ§ âš›ï¸ QBNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ")
    print("   è„³å‹æ•£åœ¨æ§‹é€  vs å±¤çŠ¶æ§‹é€ ")
    print("=" * 70)
    
    all_results = {}
    
    # 1. ç·šå½¢å›å¸°
    all_results['linear'] = compare_linear_regression()
    
    # 2. éç·šå½¢å›å¸°
    all_results['nonlinear'] = compare_nonlinear_regression()
    
    # 3. å¤šå¤‰é‡å›å¸°
    all_results['multivariate'] = compare_multivariate_regression()
    
    # 4. å¤šé …å¼å›å¸°
    all_results['polynomial'] = compare_polynomial_regression()
    
    # 5. åˆ†é¡
    all_results['classification'] = compare_classification()
    
    # ===== ç·åˆã‚µãƒãƒªãƒ¼ =====
    print("\n" + "=" * 70)
    print("ğŸ“Š ç·åˆæ¯”è¼ƒã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QBNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒçµæœ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ã‚¿ã‚¹ã‚¯          â”‚   è„³å‹æ•£åœ¨æ§‹é€       â”‚   å±¤çŠ¶æ§‹é€          â”‚ å‹è€…   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€ â”‚""")
    
    brain_wins = 0
    layered_wins = 0
    
    # å›å¸°ã‚¿ã‚¹ã‚¯
    for task_name, display_name in [
        ('linear', 'ç·šå½¢å›å¸°'),
        ('nonlinear', 'éç·šå½¢å›å¸°'),
        ('multivariate', 'å¤šå¤‰é‡å›å¸°'),
        ('polynomial', 'å¤šé …å¼å›å¸°'),
    ]:
        if task_name in all_results:
            r = all_results[task_name]
            brain_r2 = r['brain']['RÂ²']
            layered_r2 = r['layered']['RÂ²']
            
            if brain_r2 > layered_r2:
                winner = "ğŸ§ "
                brain_wins += 1
            elif layered_r2 > brain_r2:
                winner = "ğŸ“Š"
                layered_wins += 1
            else:
                winner = "å¼•åˆ†"
            
            print(f"â”‚  {display_name:14} â”‚ RÂ²={brain_r2:.4f}        â”‚ RÂ²={layered_r2:.4f}       â”‚  {winner}   â”‚")
    
    # åˆ†é¡ã‚¿ã‚¹ã‚¯
    if 'classification' in all_results:
        r = all_results['classification']
        brain_acc = r['brain']['Accuracy']
        layered_acc = r['layered']['Accuracy']
        
        if brain_acc > layered_acc:
            winner = "ğŸ§ "
            brain_wins += 1
        elif layered_acc > brain_acc:
            winner = "ğŸ“Š"
            layered_wins += 1
        else:
            winner = "å¼•åˆ†"
        
        print(f"â”‚  {'XORåˆ†é¡':14} â”‚ Acc={brain_acc:.0f}%         â”‚ Acc={layered_acc:.0f}%        â”‚  {winner}   â”‚")
    
    print("""â”‚                                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤""")
    
    print(f"â”‚  å‹æ•—: ğŸ§  è„³å‹={brain_wins}å‹  ğŸ“Š å±¤çŠ¶={layered_wins}å‹                               â”‚")
    
    # å¹³å‡æ¯”è¼ƒ
    brain_r2_avg = np.mean([all_results[t]['brain']['RÂ²'] for t in ['linear', 'nonlinear', 'multivariate', 'polynomial']])
    layered_r2_avg = np.mean([all_results[t]['layered']['RÂ²'] for t in ['linear', 'nonlinear', 'multivariate', 'polynomial']])
    
    brain_time_avg = np.mean([all_results[t]['brain']['Time'] for t in all_results])
    layered_time_avg = np.mean([all_results[t]['layered']['Time'] for t in all_results])
    
    print(f"â”‚                                                                      â”‚")
    print(f"â”‚  å¹³å‡RÂ²: ğŸ§  {brain_r2_avg:.4f}  ğŸ“Š {layered_r2_avg:.4f}                               â”‚")
    print(f"â”‚  å¹³å‡æ™‚é–“: ğŸ§  {brain_time_avg:.2f}ç§’  ğŸ“Š {layered_time_avg:.2f}ç§’                            â”‚")
    
    print("""â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # ç‰¹å¾´æ¯”è¼ƒ
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹å¾´æ¯”è¼ƒ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  ç‰¹å¾´              â”‚   ğŸ§  è„³å‹æ•£åœ¨æ§‹é€     â”‚   ğŸ“Š å±¤çŠ¶æ§‹é€           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  æ§‹é€               â”‚   ã‚°ãƒ©ãƒ•çŠ¶ãƒ»åˆ†æ•£å‹   â”‚   æ•´åˆ—ã—ãŸå±¤æ§‹é€        â”‚
â”‚  æ¥ç¶š              â”‚   ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ»ãƒ©ãƒ³ãƒ€ãƒ  â”‚   å…¨çµåˆãƒ»æ§‹é€ åŒ–       â”‚
â”‚  ä¿¡å·ä¼æ’­          â”‚   æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—       â”‚   é †æ¬¡ä¼æ’­             â”‚
â”‚  é‡å­ã‚‚ã¤ã‚Œ        â”‚   ä»»æ„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“   â”‚   éš£æ¥å±¤é–“ã®ã¿         â”‚
â”‚  è¡¨ç¾åŠ›            â”‚   æŸ”è»Ÿãƒ»é©å¿œçš„       â”‚   éšå±¤çš„ãƒ»æ§‹é€ åŒ–       â”‚
â”‚  è¨ˆç®—ã‚³ã‚¹ãƒˆ        â”‚   ã‚„ã‚„é«˜ã„           â”‚   åŠ¹ç‡çš„               â”‚
â”‚  ç”Ÿç‰©å­¦çš„å¦¥å½“æ€§    â”‚   é«˜ã„ï¼ˆè„³ã«è¿‘ã„ï¼‰   â”‚   ä½ã„ï¼ˆäººå·¥çš„ï¼‰       â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    # ç·è©•
    if brain_wins > layered_wins:
        overall = "ğŸ§  è„³å‹æ•£åœ¨æ§‹é€ "
        comment = "ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã‚’é”æˆ"
    elif layered_wins > brain_wins:
        overall = "ğŸ“Š å±¤çŠ¶æ§‹é€ "
        comment = "ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã‚’é”æˆ"
    else:
        overall = "å¼•ãåˆ†ã‘"
        comment = "ä¸¡è€…åŒç­‰ã®æ€§èƒ½"
    
    print(f"\nğŸ† ç·åˆå„ªå‹: {overall}")
    print(f"   {comment}")
    
    return all_results


if __name__ == '__main__':
    run_full_comparison()

