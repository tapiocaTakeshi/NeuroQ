#!/usr/bin/env python3
"""
QBNN Brain - è„³å‹æ•£åœ¨é‡å­ãƒ“ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
============================================
å¾“æ¥ã®å±¤çŠ¶æ§‹é€ ã§ã¯ãªãã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ï¼ˆé‡å­ãƒ“ãƒƒãƒˆï¼‰ãŒ
ãƒãƒ©ãƒãƒ©ã«æ•£ã‚‰ã°ã£ãŸè„³ã®ã‚ˆã†ãªæ§‹é€ 

ç‰¹å¾´:
- å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒç‹¬ç«‹ã—ãŸé‡å­ãƒ“ãƒƒãƒˆï¼ˆAPQBï¼‰
- ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã®æ¥ç¶šã¯ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆãƒ©ãƒ³ãƒ€ãƒ /å­¦ç¿’å¯èƒ½ï¼‰
- å±¤ã§ã¯ãªãã€æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¿¡å·ãŒä¼æ’­
- é‡å­ã‚‚ã¤ã‚ŒãŒä»»æ„ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã§ç™ºç”Ÿ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
import math
from typing import List, Dict, Tuple, Optional
import matplotlib.pyplot as plt


# ========================================
# å˜ä¸€é‡å­ãƒ“ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
# ========================================

class QuantumNeuron:
    """
    å˜ä¸€ã®é‡å­ãƒ“ãƒƒãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
    
    APQBç†è«–ã«åŸºã¥ã:
    - Î¸: å†…éƒ¨è§’åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    - r = cos(2Î¸): ç›¸é–¢ä¿‚æ•°
    - T = |sin(2Î¸)|: æ¸©åº¦ï¼ˆã‚†ã‚‰ãï¼‰
    """
    
    def __init__(self, neuron_id: int):
        self.id = neuron_id
        
        # é‡å­çŠ¶æ…‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.theta = random.uniform(0.3, 1.2)  # Î¸ âˆˆ [0, Ï€/2]
        
        # æ´»æ€§åŒ–å€¤ï¼ˆå¤å…¸çš„ãªå‡ºåŠ›ï¼‰
        self.activation = 0.0
        
        # æ¥ç¶šå…ˆãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨é‡ã¿ {neuron_id: weight}
        self.connections: Dict[int, float] = {}
        
        # ã‚‚ã¤ã‚Œãƒ†ãƒ³ã‚½ãƒ«ï¼ˆæ¥ç¶šå…ˆã¨ã®é‡å­ã‚‚ã¤ã‚Œå¼·åº¦ï¼‰
        self.entanglement: Dict[int, float] = {}
        
        # å…¥åŠ›ãƒãƒƒãƒ•ã‚¡
        self.input_buffer = 0.0
        
        # ç™ºç«å±¥æ­´
        self.spike_history: List[float] = []
    
    @property
    def r(self) -> float:
        """ç›¸é–¢ä¿‚æ•°"""
        return math.cos(2 * self.theta)
    
    @property
    def T(self) -> float:
        """æ¸©åº¦ï¼ˆã‚†ã‚‰ãï¼‰"""
        return abs(math.sin(2 * self.theta))
    
    @property
    def state_0_prob(self) -> float:
        """|0âŸ©çŠ¶æ…‹ã®ç¢ºç‡"""
        return math.cos(self.theta) ** 2
    
    @property
    def state_1_prob(self) -> float:
        """|1âŸ©çŠ¶æ…‹ã®ç¢ºç‡"""
        return math.sin(self.theta) ** 2
    
    def measure(self) -> int:
        """é‡å­æ¸¬å®šï¼ˆ0 or 1ï¼‰"""
        return 1 if random.random() < self.state_1_prob else 0
    
    def receive_input(self, value: float, from_neuron: int):
        """ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰å…¥åŠ›ã‚’å—ã‘å–ã‚‹"""
        weight = self.connections.get(from_neuron, 0.0)
        entangle = self.entanglement.get(from_neuron, 0.0)
        
        # é‡å­ã‚‚ã¤ã‚Œè£œæ­£
        quantum_correction = entangle * self.r * value
        
        self.input_buffer += weight * value + quantum_correction
    
    def update(self, learning_rate: float = 0.01):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³çŠ¶æ…‹ã‚’æ›´æ–°"""
        # å…¥åŠ›ã«åŸºã¥ã„ã¦Î¸ã‚’æ›´æ–°
        # tanhæ´»æ€§åŒ–
        self.activation = math.tanh(self.input_buffer)
        
        # Î¸ã®æ›´æ–°ï¼ˆé‡å­çŠ¶æ…‹ã®å¤‰åŒ–ï¼‰
        delta_theta = learning_rate * self.input_buffer * (1 - self.activation ** 2)
        self.theta = max(0.1, min(1.47, self.theta + delta_theta))  # Ï€/2 - Îµ
        
        # ã‚¹ãƒ‘ã‚¤ã‚¯è¨˜éŒ²
        self.spike_history.append(self.activation)
        if len(self.spike_history) > 100:
            self.spike_history.pop(0)
        
        # ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢
        self.input_buffer = 0.0
    
    def connect_to(self, target_id: int, weight: float = None, entangle: float = None):
        """ä»–ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«æ¥ç¶š"""
        if weight is None:
            weight = random.gauss(0, 0.5)
        if entangle is None:
            entangle = random.uniform(0.1, 0.5)
        
        self.connections[target_id] = weight
        self.entanglement[target_id] = entangle


# ========================================
# æ•£åœ¨å‹QBNNï¼ˆè„³å‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰
# ========================================

class QBNNBrain:
    """
    è„³å‹æ•£åœ¨é‡å­ãƒ“ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆå‹•çš„å…¥å‡ºåŠ›ç‰ˆï¼‰
    
    - ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±¤ã§ã¯ãªããƒãƒ©ãƒãƒ©ã«å­˜åœ¨
    - æ¥ç¶šã¯ã‚°ãƒ©ãƒ•æ§‹é€ ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰
    - å…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯å‹•çš„ã«å¤‰åŒ–ï¼ˆæœ¬ç‰©ã®è„³ã®ã‚ˆã†ã«ï¼‰
    - æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¿¡å·ãŒä¼æ’­
    
    ä¾‹ï¼š
    - ç›®ã‹ã‚‰ã®å…¥åŠ› â†’ ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç¾¤ãŒå—ä¿¡
    - è€³ã‹ã‚‰ã®å…¥åŠ› â†’ åˆ¥ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ç¾¤ãŒå—ä¿¡
    - å‡ºåŠ›ã‚‚åŒæ§˜ã«ã€çŠ¶æ³ã«å¿œã˜ã¦ç•°ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰å–å¾—
    """
    
    def __init__(self, num_neurons: int = 100, 
                 connection_density: float = 0.15,
                 plasticity: float = 0.1):
        """
        Args:
            num_neurons: ç·ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            connection_density: æ¥ç¶šå¯†åº¦ (0-1)
            plasticity: å¯å¡‘æ€§ï¼ˆæ¥ç¶šã®å¤‰åŒ–ã—ã‚„ã™ã•ï¼‰
        """
        self.num_neurons = num_neurons
        self.connection_density = connection_density
        self.plasticity = plasticity
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ä½œæˆï¼ˆã™ã¹ã¦åŒç­‰ã€å…¥åŠ›ã«ã‚‚å‡ºåŠ›ã«ã‚‚ãªã‚Œã‚‹ï¼‰
        self.neurons: Dict[int, QuantumNeuron] = {}
        for i in range(num_neurons):
            self.neurons[i] = QuantumNeuron(i)
        
        # å…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯å›ºå®šã—ãªã„ï¼ˆå‹•çš„ã«é¸æŠï¼‰
        self.all_neuron_ids = list(range(num_neurons))
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã€Œæ„Ÿå—æ€§ã€ï¼ˆå…¥åŠ›ã‚’å—ã‘ã‚„ã™ã•ï¼‰
        self.sensitivity = {i: random.uniform(0.3, 1.0) for i in range(num_neurons)}
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ã€Œå‡ºåŠ›å‚¾å‘ã€ï¼ˆå‡ºåŠ›ã«é¸ã°ã‚Œã‚„ã™ã•ï¼‰
        self.output_tendency = {i: random.uniform(0.3, 1.0) for i in range(num_neurons)}
        
        # ãƒ©ãƒ³ãƒ€ãƒ æ¥ç¶šã‚’ç”Ÿæˆ
        self._create_connections(connection_density)
        
        # å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”¨
        self.global_lambda = 0.35  # ã‚‚ã¤ã‚Œå¼·åº¦
    
    def _create_connections(self, density: float):
        """ãƒ©ãƒ³ãƒ€ãƒ ãªã‚°ãƒ©ãƒ•æ¥ç¶šã‚’ç”Ÿæˆï¼ˆå®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ ï¼‰"""
        for i in range(self.num_neurons):
            for j in range(self.num_neurons):
                if i != j and random.random() < density:
                    weight = random.gauss(0, 0.3)
                    entangle = random.uniform(0.1, 0.4)
                    self.neurons[i].connect_to(j, weight, entangle)
    
    def select_input_neurons(self, input_size: int, input_type: str = None) -> List[int]:
        """
        å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å‹•çš„ã«é¸æŠï¼ˆè„³ã®æ„Ÿè¦šå™¨å®˜ã®ã‚ˆã†ã«ï¼‰
        
        Args:
            input_size: å¿…è¦ãªå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            input_type: å…¥åŠ›ã‚¿ã‚¤ãƒ—ï¼ˆ'visual', 'audio', 'touch'ãªã©ï¼‰
        
        Returns:
            é¸æŠã•ã‚ŒãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®ID
        """
        # æ„Ÿå—æ€§ã«åŸºã¥ã„ã¦ç¢ºç‡çš„ã«é¸æŠ
        weights = [self.sensitivity[i] for i in self.all_neuron_ids]
        total = sum(weights)
        probs = [w / total for w in weights]
        
        # input_typeã«åŸºã¥ã„ã¦ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã‚‹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if input_type == 'visual':
            # è¦–è¦šï¼šå¾ŒåŠã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒã‚¤ã‚¢ã‚¹
            for i in range(len(probs)):
                if i > self.num_neurons * 0.6:
                    probs[i] *= 2.0
        elif input_type == 'audio':
            # è´è¦šï¼šä¸­é–“ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒã‚¤ã‚¢ã‚¹
            for i in range(len(probs)):
                if self.num_neurons * 0.3 < i < self.num_neurons * 0.7:
                    probs[i] *= 2.0
        elif input_type == 'touch':
            # è§¦è¦šï¼šå‰åŠã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒã‚¤ã‚¢ã‚¹
            for i in range(len(probs)):
                if i < self.num_neurons * 0.4:
                    probs[i] *= 2.0
        
        # æ­£è¦åŒ–
        total = sum(probs)
        probs = [p / total for p in probs]
        
        # é‡è¤‡ãªã—ã§é¸æŠ
        selected = []
        available = list(self.all_neuron_ids)
        available_probs = list(probs)
        
        for _ in range(min(input_size, self.num_neurons)):
            if not available:
                break
            # æ­£è¦åŒ–
            total = sum(available_probs)
            if total == 0:
                break
            normalized = [p / total for p in available_probs]
            
            idx = random.choices(range(len(available)), weights=normalized, k=1)[0]
            selected.append(available[idx])
            available.pop(idx)
            available_probs.pop(idx)
        
        return selected
    
    def select_output_neurons(self, output_size: int, output_type: str = None) -> List[int]:
        """
        å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å‹•çš„ã«é¸æŠï¼ˆè„³ã®é‹å‹•é‡ã®ã‚ˆã†ã«ï¼‰
        
        Args:
            output_size: å¿…è¦ãªå‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            output_type: å‡ºåŠ›ã‚¿ã‚¤ãƒ—ï¼ˆ'motor', 'speech', 'emotion'ãªã©ï¼‰
        """
        # å‡ºåŠ›å‚¾å‘ã«åŸºã¥ã„ã¦ç¢ºç‡çš„ã«é¸æŠ
        weights = [self.output_tendency[i] for i in self.all_neuron_ids]
        
        # æœ€ã‚‚æ´»æ€§åŒ–ã—ã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ãƒã‚¤ã‚¢ã‚¹
        for i in self.all_neuron_ids:
            weights[i] *= (1.0 + abs(self.neurons[i].activation))
        
        total = sum(weights)
        probs = [w / total for w in weights]
        
        # output_typeã«åŸºã¥ã„ã¦ãƒã‚¤ã‚¢ã‚¹
        if output_type == 'motor':
            for i in range(len(probs)):
                if i < self.num_neurons * 0.3:
                    probs[i] *= 2.0
        elif output_type == 'speech':
            for i in range(len(probs)):
                if self.num_neurons * 0.4 < i < self.num_neurons * 0.6:
                    probs[i] *= 2.0
        
        # æ­£è¦åŒ–
        total = sum(probs)
        probs = [p / total for p in probs]
        
        # é¸æŠ
        selected = []
        available = list(self.all_neuron_ids)
        available_probs = list(probs)
        
        for _ in range(min(output_size, self.num_neurons)):
            if not available:
                break
            total = sum(available_probs)
            if total == 0:
                break
            normalized = [p / total for p in available_probs]
            
            idx = random.choices(range(len(available)), weights=normalized, k=1)[0]
            selected.append(available[idx])
            available.pop(idx)
            available_probs.pop(idx)
        
        return selected
    
    def forward(self, inputs: List[float], 
                input_neurons: List[int] = None,
                output_neurons: List[int] = None,
                output_size: int = 5,
                time_steps: int = 5,
                input_type: str = None,
                output_type: str = None) -> Tuple[List[float], List[int], List[int]]:
        """
        å‰å‘ãä¼æ’­ï¼ˆå‹•çš„å…¥å‡ºåŠ›ç‰ˆï¼‰
        
        Args:
            inputs: å…¥åŠ›å€¤ã®ãƒªã‚¹ãƒˆ
            input_neurons: å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®IDï¼ˆNoneãªã‚‰è‡ªå‹•é¸æŠï¼‰
            output_neurons: å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®IDï¼ˆNoneãªã‚‰è‡ªå‹•é¸æŠï¼‰
            output_size: å‡ºåŠ›ã‚µã‚¤ã‚ºï¼ˆoutput_neuronsãŒNoneã®å ´åˆï¼‰
            time_steps: ä¿¡å·ä¼æ’­ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
            input_type: å…¥åŠ›ã‚¿ã‚¤ãƒ—ï¼ˆé¸æŠã«ãƒã‚¤ã‚¢ã‚¹ï¼‰
            output_type: å‡ºåŠ›ã‚¿ã‚¤ãƒ—ï¼ˆé¸æŠã«ãƒã‚¤ã‚¢ã‚¹ï¼‰
        
        Returns:
            (å‡ºåŠ›å€¤, ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³, ä½¿ç”¨ã—ãŸå‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³)
        """
        # å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å‹•çš„ã«é¸æŠ
        if input_neurons is None:
            input_neurons = self.select_input_neurons(len(inputs), input_type)
        
        # å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«å€¤ã‚’è¨­å®š
        for i, val in enumerate(inputs):
            if i < len(input_neurons):
                neuron_id = input_neurons[i]
                self.neurons[neuron_id].activation = val
                self.neurons[neuron_id].theta = 0.25 + 0.5 * (val + 1) / 2
                # æ„Ÿå—æ€§ã‚’æ›´æ–°ï¼ˆä½¿ã‚ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯æ„Ÿå—æ€§ãŒä¸ŠãŒã‚‹ï¼‰
                self.sensitivity[neuron_id] = min(1.0, self.sensitivity[neuron_id] + self.plasticity * 0.1)
        
        # æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¿¡å·ä¼æ’­
        for t in range(time_steps):
            # å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‹ã‚‰ä¿¡å·ã‚’é€ä¿¡
            for neuron_id, neuron in self.neurons.items():
                for target_id, weight in neuron.connections.items():
                    if target_id in self.neurons:
                        # é‡å­æ¸¬å®šã«åŸºã¥ãç¢ºç‡çš„ç™ºç«
                        if random.random() < 0.7 + 0.3 * abs(neuron.activation):
                            self.neurons[target_id].receive_input(
                                neuron.activation, neuron_id
                            )
            
            # å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æ›´æ–°
            for neuron in self.neurons.values():
                neuron.update(learning_rate=0.05)
            
            # æ¥ç¶šã®å¯å¡‘æ€§ï¼ˆãƒ˜ãƒ–å‰‡çš„ãªæ›´æ–°ï¼‰
            if random.random() < self.plasticity:
                self._update_connections()
        
        # å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å‹•çš„ã«é¸æŠ
        if output_neurons is None:
            output_neurons = self.select_output_neurons(output_size, output_type)
        
        # å‡ºåŠ›å‚¾å‘ã‚’æ›´æ–°ï¼ˆä½¿ã‚ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯å‡ºåŠ›å‚¾å‘ãŒä¸ŠãŒã‚‹ï¼‰
        for neuron_id in output_neurons:
            self.output_tendency[neuron_id] = min(1.0, self.output_tendency[neuron_id] + self.plasticity * 0.1)
        
        # å‡ºåŠ›ã‚’åé›†
        outputs = [self.neurons[i].activation for i in output_neurons]
        return outputs, input_neurons, output_neurons
    
    def _update_connections(self):
        """æ¥ç¶šã®å¯å¡‘æ€§æ›´æ–°ï¼ˆãƒ˜ãƒ–å‰‡ï¼‰"""
        for neuron_id, neuron in self.neurons.items():
            for target_id in list(neuron.connections.keys()):
                if target_id in self.neurons:
                    target = self.neurons[target_id]
                    
                    # ãƒ˜ãƒ–å‰‡ï¼šåŒæ™‚ã«ç™ºç«ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã®æ¥ç¶šã‚’å¼·åŒ–
                    if abs(neuron.activation) > 0.5 and abs(target.activation) > 0.5:
                        # åŒç¬¦å·ãªã‚‰å¼·åŒ–ã€ç•°ç¬¦å·ãªã‚‰å¼±åŒ–
                        if neuron.activation * target.activation > 0:
                            neuron.connections[target_id] *= 1.01
                        else:
                            neuron.connections[target_id] *= 0.99
                    
                    # æ¥ç¶šã®æ¸›è¡°
                    neuron.connections[target_id] *= 0.999
        
        # æ–°ã—ã„æ¥ç¶šã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è¿½åŠ ï¼ˆä½ç¢ºç‡ï¼‰
        if random.random() < 0.01:
            i = random.randint(0, self.num_neurons - 1)
            j = random.randint(0, self.num_neurons - 1)
            if i != j and j not in self.neurons[i].connections:
                self.neurons[i].connect_to(j, random.gauss(0, 0.1), random.uniform(0.1, 0.3))
    
    def get_quantum_state(self) -> Dict:
        """å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é‡å­çŠ¶æ…‹ã‚’å–å¾—"""
        states = {}
        for neuron_id, neuron in self.neurons.items():
            states[neuron_id] = {
                'theta': neuron.theta,
                'r': neuron.r,
                'T': neuron.T,
                'activation': neuron.activation,
                'p0': neuron.state_0_prob,
                'p1': neuron.state_1_prob,
                'sensitivity': self.sensitivity[neuron_id],
                'output_tendency': self.output_tendency[neuron_id],
            }
        return states
    
    def measure_all(self) -> List[int]:
        """å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é‡å­æ¸¬å®š"""
        return [neuron.measure() for neuron in self.neurons.values()]
    
    def get_most_active_neurons(self, top_k: int = 10) -> List[Tuple[int, float]]:
        """æœ€ã‚‚æ´»æ€§åŒ–ã—ã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’å–å¾—"""
        activations = [(i, abs(n.activation)) for i, n in self.neurons.items()]
        activations.sort(key=lambda x: -x[1])
        return activations[:top_k]
    
    def visualize(self, filename: str = None, 
                  last_input_neurons: List[int] = None,
                  last_output_neurons: List[int] = None):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã®å¯è¦–åŒ–ï¼ˆå‹•çš„å…¥å‡ºåŠ›å¯¾å¿œï¼‰"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        
        # 1. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é…ç½®ã¨æ¥ç¶š
        ax1 = axes[0]
        ax1.set_title('ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ï¼ˆå‹•çš„å…¥å‡ºåŠ›ï¼‰')
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ä½ç½®ã‚’å††å½¢ã«é…ç½®ï¼ˆè„³ã®ã‚ˆã†ã«ï¼‰
        positions = {}
        for i in range(self.num_neurons):
            angle = 2 * np.pi * i / self.num_neurons
            radius = 0.8 + 0.2 * self.sensitivity[i]
            positions[i] = (np.cos(angle) * radius, np.sin(angle) * radius)
        
        # æ¥ç¶šã‚’æç”»
        for neuron_id, neuron in self.neurons.items():
            x1, y1 = positions[neuron_id]
            for target_id, weight in neuron.connections.items():
                if target_id in positions:
                    x2, y2 = positions[target_id]
                    color = 'blue' if weight > 0 else 'red'
                    alpha = min(abs(weight), 1.0) * 0.2
                    ax1.plot([x1, x2], [y1, y2], color=color, alpha=alpha, linewidth=0.3)
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æç”»
        for i, (x, y) in positions.items():
            # æœ€å¾Œã«ä½¿ã‚ã‚ŒãŸå…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’è‰²åˆ†ã‘
            if last_input_neurons and i in last_input_neurons:
                color = 'green'
                size = 80
            elif last_output_neurons and i in last_output_neurons:
                color = 'red'
                size = 80
            else:
                # æ´»æ€§åŒ–åº¦ã«å¿œã˜ãŸè‰²
                act = abs(self.neurons[i].activation)
                color = plt.cm.viridis(act)
                size = 30 + 50 * act
            ax1.scatter(x, y, c=[color], s=size, zorder=5, alpha=0.7)
        
        ax1.set_xlim(-1.3, 1.3)
        ax1.set_ylim(-1.3, 1.3)
        ax1.set_aspect('equal')
        
        # 2. æ„Ÿå—æ€§ã¨å‡ºåŠ›å‚¾å‘
        ax2 = axes[1]
        ax2.set_title('æ„Ÿå—æ€§ vs å‡ºåŠ›å‚¾å‘')
        sens = [self.sensitivity[i] for i in range(self.num_neurons)]
        out_tend = [self.output_tendency[i] for i in range(self.num_neurons)]
        colors = [abs(self.neurons[i].activation) for i in range(self.num_neurons)]
        scatter = ax2.scatter(sens, out_tend, c=colors, cmap='plasma', alpha=0.6)
        ax2.set_xlabel('æ„Ÿå—æ€§ï¼ˆå…¥åŠ›ã•ã‚Œã‚„ã™ã•ï¼‰')
        ax2.set_ylabel('å‡ºåŠ›å‚¾å‘ï¼ˆå‡ºåŠ›ã•ã‚Œã‚„ã™ã•ï¼‰')
        plt.colorbar(scatter, ax=ax2, label='æ´»æ€§åŒ–åº¦')
        
        # 3. r-Tç©ºé–“
        ax3 = axes[2]
        ax3.set_title('r-Tç©ºé–“ï¼ˆç›¸é–¢-æ¸©åº¦ï¼‰')
        rs = [n.r for n in self.neurons.values()]
        Ts = [n.T for n in self.neurons.values()]
        activations = [abs(n.activation) for n in self.neurons.values()]
        scatter = ax3.scatter(rs, Ts, c=activations, cmap='hot', alpha=0.6)
        ax3.set_xlabel('r (ç›¸é–¢)')
        ax3.set_ylabel('T (æ¸©åº¦)')
        plt.colorbar(scatter, ax=ax3, label='æ´»æ€§åŒ–åº¦')
        
        # rÂ²+TÂ²=1 ã®å††
        theta_circle = np.linspace(0, np.pi/2, 100)
        ax3.plot(np.cos(2*theta_circle), np.abs(np.sin(2*theta_circle)), 
                'k--', alpha=0.3, label='rÂ²+TÂ²=1')
        ax3.legend()
        
        plt.tight_layout()
        
        if filename:
            plt.savefig(filename, dpi=150, bbox_inches='tight')
            print(f"ğŸ“Š ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {filename}")
        
        plt.close()
        return fig


# ========================================
# PyTorchç‰ˆï¼ˆå­¦ç¿’å¯èƒ½ã€å‹•çš„å…¥å‡ºåŠ›å¯¾å¿œï¼‰
# ========================================

class QBNNBrainTorch(nn.Module):
    """
    PyTorchç‰ˆ è„³å‹QBNNï¼ˆå­¦ç¿’å¯èƒ½ã€å‹•çš„å…¥å‡ºåŠ›ï¼‰
    
    å…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå›ºå®šã§ã¯ãªãã€å‹•çš„ã«é¸æŠã•ã‚Œã‚‹
    """
    
    def __init__(self, num_neurons: int = 50, 
                 max_input_size: int = 20, 
                 max_output_size: int = 10,
                 connection_density: float = 0.2):
        super().__init__()
        
        self.num_neurons = num_neurons
        self.max_input_size = max_input_size
        self.max_output_size = max_output_size
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é‡å­çŠ¶æ…‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ Î¸
        self.theta = nn.Parameter(torch.rand(num_neurons) * 1.0 + 0.25)
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ„Ÿå—æ€§ï¼ˆå…¥åŠ›ã•ã‚Œã‚„ã™ã•ï¼‰
        self.sensitivity = nn.Parameter(torch.rand(num_neurons) * 0.5 + 0.3)
        
        # å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å‡ºåŠ›å‚¾å‘
        self.output_tendency = nn.Parameter(torch.rand(num_neurons) * 0.5 + 0.3)
        
        # æ¥ç¶šè¡Œåˆ—ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ï¼‰
        mask = torch.rand(num_neurons, num_neurons) < connection_density
        mask.fill_diagonal_(False)  # è‡ªå·±æ¥ç¶šãªã—
        self.register_buffer('connection_mask', mask.float())
        
        # é‡ã¿è¡Œåˆ—
        self.weights = nn.Parameter(torch.randn(num_neurons, num_neurons) * 0.3)
        
        # ã‚‚ã¤ã‚Œãƒ†ãƒ³ã‚½ãƒ«
        self.J = nn.Parameter(torch.randn(num_neurons, num_neurons) * 0.1)
        
        # ã‚‚ã¤ã‚Œå¼·åº¦
        self.lambda_entangle = nn.Parameter(torch.tensor(0.35))
        
        # æ±ç”¨å…¥åŠ›å°„å½±ï¼ˆä»»æ„ã‚µã‚¤ã‚ºã®å…¥åŠ›ã‚’å—ã‘å–ã‚Œã‚‹ï¼‰
        self.input_proj = nn.Linear(max_input_size, num_neurons)
        self.output_proj = nn.Linear(num_neurons, max_output_size)
        
        # æœ€å¾Œã«ä½¿ç”¨ã—ãŸå…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        self.last_input_neurons = None
        self.last_output_neurons = None
    
    def get_r(self) -> torch.Tensor:
        """ç›¸é–¢ä¿‚æ•° r = cos(2Î¸)"""
        return torch.cos(2 * self.theta)
    
    def get_T(self) -> torch.Tensor:
        """æ¸©åº¦ T = |sin(2Î¸)|"""
        return torch.abs(torch.sin(2 * self.theta))
    
    def select_neurons(self, tendency: torch.Tensor, k: int, 
                       temperature: float = 1.0) -> torch.Tensor:
        """å‚¾å‘ã«åŸºã¥ã„ã¦ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç¢ºç‡çš„ã«é¸æŠ"""
        # ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã§ç¢ºç‡ã«å¤‰æ›
        probs = F.softmax(tendency / temperature, dim=-1)
        
        # Gumbel-Softmaxçš„ãªé¸æŠï¼ˆå¾®åˆ†å¯èƒ½ï¼‰
        noise = -torch.log(-torch.log(torch.rand_like(probs) + 1e-8) + 1e-8)
        scores = (torch.log(probs + 1e-8) + noise) / temperature
        
        # Top-Ké¸æŠ
        _, indices = torch.topk(scores, k)
        return indices
    
    def forward(self, x: torch.Tensor, 
                input_size: int = None,
                output_size: int = None,
                time_steps: int = 3,
                dynamic_selection: bool = True) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ãä¼æ’­ï¼ˆå‹•çš„å…¥å‡ºåŠ›ç‰ˆï¼‰
        
        Args:
            x: (batch, input_dim) å…¥åŠ›
            input_size: ä½¿ç”¨ã™ã‚‹å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            output_size: ä½¿ç”¨ã™ã‚‹å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°
            time_steps: ä¼æ’­ã‚¹ãƒ†ãƒƒãƒ—æ•°
            dynamic_selection: å‹•çš„ã«ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸æŠã™ã‚‹ã‹
        
        Returns:
            (output, input_neurons, output_neurons)
        """
        batch_size = x.size(0)
        actual_input_size = x.size(1)
        
        if input_size is None:
            input_size = min(actual_input_size, self.num_neurons // 2)
        if output_size is None:
            output_size = self.max_output_size
        
        # å…¥åŠ›ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        if actual_input_size < self.max_input_size:
            padding = torch.zeros(batch_size, self.max_input_size - actual_input_size, device=x.device)
            x_padded = torch.cat([x, padding], dim=1)
        else:
            x_padded = x[:, :self.max_input_size]
        
        # åˆæœŸçŠ¶æ…‹ï¼šå…¥åŠ›ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«å°„å½±
        state = self.input_proj(x_padded)  # (batch, num_neurons)
        
        # å‹•çš„ã«å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸æŠ
        if dynamic_selection:
            input_neurons = self.select_neurons(self.sensitivity, input_size)
            # é¸æŠã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«å…¥åŠ›ã‚’é›†ä¸­
            input_mask = torch.zeros(self.num_neurons, device=x.device)
            input_mask[input_neurons] = 1.0
            state = state * input_mask
        else:
            input_neurons = torch.arange(input_size, device=x.device)
        
        self.last_input_neurons = input_neurons
        
        # æœ‰åŠ¹ãªé‡ã¿ï¼ˆãƒã‚¹ã‚¯é©ç”¨ï¼‰
        effective_weights = self.weights * self.connection_mask
        
        # æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¼æ’­
        for t in range(time_steps):
            # é€šå¸¸ã®ä¿¡å·ä¼æ’­
            signal = torch.matmul(state, effective_weights)  # (batch, num_neurons)
            
            # é‡å­ã‚‚ã¤ã‚Œè£œæ­£ï¼ˆåŠ¹ç‡åŒ–ç‰ˆï¼‰
            s = torch.tanh(state)  # æ­£è¦åŒ– [-1, 1]
            J_masked = self.J * self.connection_mask
            
            # ãƒãƒƒãƒå‡¦ç†
            entangle_correction = torch.einsum('bi,ij,bj->bj', s, J_masked, s)
            
            # æœ‰åŠ¹å…¥åŠ›
            effective_input = signal + self.lambda_entangle * entangle_correction
            
            # æ´»æ€§åŒ–ï¼ˆé‡å­çš„ã‚†ã‚‰ãã‚’å«ã‚€ï¼‰
            T = self.get_T()  # (num_neurons,)
            noise = torch.randn_like(state) * T.unsqueeze(0) * 0.1
            state = torch.tanh(effective_input + noise)
        
        # å‹•çš„ã«å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’é¸æŠ
        if dynamic_selection:
            # æ´»æ€§åŒ–åº¦ã¨å‡ºåŠ›å‚¾å‘ã‚’çµ„ã¿åˆã‚ã›
            combined_tendency = self.output_tendency + state.mean(0).abs()
            output_neurons = self.select_neurons(combined_tendency, output_size)
        else:
            output_neurons = torch.arange(self.num_neurons - output_size, self.num_neurons, device=x.device)
        
        self.last_output_neurons = output_neurons
        
        # å‡ºåŠ›å°„å½±
        output = self.output_proj(state)
        output = output[:, :output_size]
        
        return output, input_neurons, output_neurons
    
    def get_quantum_info(self) -> Dict:
        """é‡å­æƒ…å ±ã‚’å–å¾—"""
        with torch.no_grad():
            return {
                'theta_mean': self.theta.mean().item(),
                'theta_std': self.theta.std().item(),
                'r_mean': self.get_r().mean().item(),
                'T_mean': self.get_T().mean().item(),
                'lambda': self.lambda_entangle.item(),
                'connections': self.connection_mask.sum().item(),
                'sensitivity_mean': self.sensitivity.mean().item(),
                'output_tendency_mean': self.output_tendency.mean().item(),
            }


# ========================================
# ãƒ‡ãƒ¢
# ========================================

def demo_brain_qbnn():
    """è„³å‹QBNNã®ãƒ‡ãƒ¢ï¼ˆå‹•çš„å…¥å‡ºåŠ›ç‰ˆï¼‰"""
    print("=" * 60)
    print("ğŸ§  QBNN Brain - è„³å‹æ•£åœ¨é‡å­ãƒ“ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
    print("   å…¥åŠ›/å‡ºåŠ›ãŒå‹•çš„ã«å¤‰åŒ–ã™ã‚‹æœ¬ç‰©ã®è„³ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«")
    print("=" * 60)
    
    # ç´”ç²‹Pythonç‰ˆ
    print("\nğŸ“Œ ç´”ç²‹Pythonç‰ˆï¼ˆ50ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€å‹•çš„å…¥å‡ºåŠ›ï¼‰")
    print("-" * 40)
    
    brain = QBNNBrain(
        num_neurons=50,
        connection_density=0.15,
        plasticity=0.1
    )
    
    # ç•°ãªã‚‹å…¥åŠ›ã‚¿ã‚¤ãƒ—ã§ãƒ†ã‚¹ãƒˆ
    print("\nğŸ”¹ è¦–è¦šå…¥åŠ›ãƒ†ã‚¹ãƒˆ:")
    inputs = [0.5, -0.3, 0.8, -0.1, 0.6]
    outputs, in_neurons, out_neurons = brain.forward(
        inputs, 
        output_size=3,
        time_steps=5,
        input_type='visual',
        output_type='motor'
    )
    print(f"   å…¥åŠ›: {inputs}")
    print(f"   ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {in_neurons}")
    print(f"   ä½¿ç”¨ã—ãŸå‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {out_neurons}")
    print(f"   å‡ºåŠ›: {[f'{o:.4f}' for o in outputs]}")
    
    print("\nğŸ”¹ è´è¦šå…¥åŠ›ãƒ†ã‚¹ãƒˆï¼ˆåŒã˜å…¥åŠ›ã€ç•°ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é¸æŠï¼‰:")
    outputs2, in_neurons2, out_neurons2 = brain.forward(
        inputs, 
        output_size=3,
        time_steps=5,
        input_type='audio',
        output_type='speech'
    )
    print(f"   ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {in_neurons2}")
    print(f"   ä½¿ç”¨ã—ãŸå‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {out_neurons2}")
    print(f"   å‡ºåŠ›: {[f'{o:.4f}' for o in outputs2]}")
    
    # å…¥åŠ›/å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå¤‰ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    print(f"\nâš›ï¸ å‹•çš„é¸æŠã®ç¢ºèª:")
    print(f"   å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŒã˜: {set(in_neurons) == set(in_neurons2)}")
    print(f"   å‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŒã˜: {set(out_neurons) == set(out_neurons2)}")
    
    # æœ€ã‚‚æ´»æ€§åŒ–ã—ã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
    print("\nğŸ”¥ æœ€ã‚‚æ´»æ€§åŒ–ã—ã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³:")
    active = brain.get_most_active_neurons(top_k=5)
    for neuron_id, activation in active:
        print(f"   ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³{neuron_id}: æ´»æ€§åŒ–={activation:.4f}")
    
    # é‡å­æ¸¬å®š
    measurements = brain.measure_all()
    print(f"\nğŸ”¬ é‡å­æ¸¬å®šçµæœ: {sum(measurements)}/{len(measurements)} ãŒ |1âŸ©")
    
    # å¯è¦–åŒ–
    brain.visualize(
        '/Users/yuyahiguchi/Program/Qubit/qbnn_brain_dynamic.png',
        last_input_neurons=in_neurons,
        last_output_neurons=out_neurons
    )
    
    # PyTorchç‰ˆ
    print("\n" + "=" * 60)
    print("ğŸ“Œ PyTorchç‰ˆï¼ˆå­¦ç¿’å¯èƒ½ã€å‹•çš„å…¥å‡ºåŠ›ï¼‰")
    print("-" * 40)
    
    model = QBNNBrainTorch(
        num_neurons=40,
        max_input_size=10,
        max_output_size=5,
        connection_density=0.2
    )
    
    # æ¨è«–ãƒ†ã‚¹ãƒˆ
    x = torch.tensor([[0.5, -0.3, 0.8, -0.1, 0.6]], dtype=torch.float32)
    output, in_idx, out_idx = model(x, input_size=5, output_size=3, time_steps=3)
    
    print(f"\nå…¥åŠ›: {x[0].tolist()}")
    print(f"ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {in_idx.tolist()}")
    print(f"ä½¿ç”¨ã—ãŸå‡ºåŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {out_idx.tolist()}")
    print(f"å‡ºåŠ›: {output[0].detach().tolist()[:3]}")
    
    # åŒã˜å…¥åŠ›ã§å†åº¦å®Ÿè¡Œï¼ˆç•°ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒé¸ã°ã‚Œã‚‹ï¼‰
    output2, in_idx2, out_idx2 = model(x, input_size=5, output_size=3, time_steps=3)
    print(f"\nğŸ”„ å†å®Ÿè¡Œ:")
    print(f"   ä½¿ç”¨ã—ãŸå…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³: {in_idx2.tolist()}")
    print(f"   å…¥åŠ›ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå¤‰åŒ–: {not torch.equal(in_idx, in_idx2)}")
    
    # é‡å­æƒ…å ±
    info = model.get_quantum_info()
    print(f"\nâš›ï¸ é‡å­æƒ…å ±:")
    print(f"   Î¸å¹³å‡: {info['theta_mean']:.4f}")
    print(f"   rå¹³å‡: {info['r_mean']:.4f}")
    print(f"   Tå¹³å‡: {info['T_mean']:.4f}")
    print(f"   Î»: {info['lambda']:.4f}")
    print(f"   æ„Ÿå—æ€§å¹³å‡: {info['sensitivity_mean']:.4f}")
    print(f"   å‡ºåŠ›å‚¾å‘å¹³å‡: {info['output_tendency_mean']:.4f}")
    
    # ç°¡å˜ãªå­¦ç¿’ãƒ†ã‚¹ãƒˆ
    print("\nğŸ“š å­¦ç¿’ãƒ†ã‚¹ãƒˆï¼ˆXORå•é¡Œï¼‰...")
    
    # XORãƒ‡ãƒ¼ã‚¿
    X = torch.tensor([
        [0, 0, 0, 0, 0],
        [0, 1, 0, 0, 0],
        [1, 0, 0, 0, 0],
        [1, 1, 0, 0, 0],
    ], dtype=torch.float32)
    
    y = torch.tensor([
        [0, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [0, 0, 0],
    ], dtype=torch.float32)
    
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.MSELoss()
    
    for epoch in range(100):
        optimizer.zero_grad()
        pred, _, _ = model(X, input_size=5, output_size=3, time_steps=3, dynamic_selection=False)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
        
        if (epoch + 1) % 20 == 0:
            print(f"   Epoch {epoch+1}: Loss = {loss.item():.4f}")
    
    # æœ€çµ‚çµæœ
    print("\nğŸ¯ å­¦ç¿’å¾Œã®äºˆæ¸¬:")
    model.eval()
    with torch.no_grad():
        pred, _, _ = model(X, input_size=5, output_size=3, time_steps=3, dynamic_selection=False)
        for i in range(4):
            input_str = f"({int(X[i,0])},{int(X[i,1])})"
            pred_val = pred[i, 0].item()
            expected = y[i, 0].item()
            status = "âœ…" if abs(pred_val - expected) < 0.3 else "âŒ"
            print(f"   {status} {input_str} â†’ äºˆæ¸¬: {pred_val:.3f}, æ­£è§£: {expected:.0f}")
    
    print("\nâœ… ãƒ‡ãƒ¢å®Œäº†ï¼")
    
    return brain, model


def compare_architectures():
    """å±¤çŠ¶ vs æ•£åœ¨å‹ã®æ¯”è¼ƒ"""
    print("=" * 60)
    print("ğŸ“Š ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¯”è¼ƒ: å±¤çŠ¶ vs æ•£åœ¨å‹")
    print("=" * 60)
    
    print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å¾“æ¥ã®å±¤çŠ¶ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   å…¥åŠ›å±¤        éš ã‚Œå±¤1       éš ã‚Œå±¤2       å‡ºåŠ›å±¤            â”‚
â”‚                                                             â”‚
â”‚    â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹                    â”‚
â”‚    â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹                    â”‚
â”‚    â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹                    â”‚
â”‚    â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹                                â”‚
â”‚    â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—‹                                â”‚
â”‚                                                             â”‚
â”‚   ç‰¹å¾´: æ•´ç„¶ã¨ã—ãŸå±¤æ§‹é€ ã€æƒ…å ±ã¯å·¦â†’å³ã«æµã‚Œã‚‹               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QBNN Brainï¼ˆè„³å‹æ•£åœ¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚           â—‹â”€â”€â”€â”€â”€â”€â”€â—‹                                        â”‚
â”‚          â•±â”‚â•²     â•±â”‚â•²                                       â”‚
â”‚    å…¥åŠ›  â—‹â”€â”¼â”€â”€â—‹â”€â”€â”€â”¼â”€â”€â—‹  å‡ºåŠ›                               â”‚
â”‚          â•²â”‚â•±  â”‚â•² â•±â”‚  â•²                                     â”‚
â”‚           â—‹â”€â”€â”€â”¼â”€â—‹â”€â”€â”€â—‹                                      â”‚
â”‚            â•²  â”‚â•±    â•±                                       â”‚
â”‚             â—‹â”€â”€â—‹â”€â”€â”€â—‹                                       â”‚
â”‚                                                             â”‚
â”‚   ç‰¹å¾´: ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒãƒãƒ©ãƒãƒ©ã«æ•£ã‚‰ã°ã‚Šã€ä»»æ„ã®æ¥ç¶šãŒå¯èƒ½      â”‚
â”‚         é‡å­ã‚‚ã¤ã‚ŒãŒä»»æ„ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã§ç™ºç”Ÿ                  â”‚
â”‚         æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¿¡å·ãŒä¼æ’­ï¼ˆéåŒæœŸçš„ï¼‰                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    print("\nâš›ï¸ QBNN Brainã®ç‰¹å¾´:")
    print("   1. å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒç‹¬ç«‹ã—ãŸé‡å­ãƒ“ãƒƒãƒˆï¼ˆAPQBï¼‰")
    print("   2. Î¸ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§çŠ¶æ…‹ã‚’è¡¨ç¾ (r=cos2Î¸, T=|sin2Î¸|)")
    print("   3. æ¥ç¶šã¯ã‚¹ãƒ‘ãƒ¼ã‚¹ãªã‚°ãƒ©ãƒ•æ§‹é€ ")
    print("   4. é‡å­ã‚‚ã¤ã‚Œï¼ˆJ ãƒ†ãƒ³ã‚½ãƒ«ï¼‰ãŒä»»æ„ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³é–“ã§ç™ºç”Ÿ")
    print("   5. æ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—ã§ä¿¡å·ãŒä¼æ’­")


if __name__ == '__main__':
    compare_architectures()
    brain, model = demo_brain_qbnn()

