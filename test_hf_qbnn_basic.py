#!/usr/bin/env python3
"""
HF-OpenAI-QBNN Pipeline ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ
===================================
ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã€ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å‹•ä½œç¢ºèª
"""

import torch
from hf_openai_qbnn_pipeline import (
    HFTokenizerWrapper,
    HFQBNNConfig,
    HFOpenAIQBNNPipeline
)


def test_tokenizer():
    """ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“ Test 1: GPT-2 Tokenizer")
    print("=" * 60)

    tokenizer = HFTokenizerWrapper('gpt2')

    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    texts = [
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯é©æ–°çš„ã§ã™",
        "The transformer model is powerful",
        "äººå·¥çŸ¥èƒ½ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°"
    ]

    for text in texts:
        tokens = tokenizer.encode(text)
        decoded = tokenizer.decode(tokens)
        print(f"\n  å…¥åŠ›: {text}")
        print(f"  ãƒˆãƒ¼ã‚¯ãƒ³ID: {tokens[:10]}... (len={len(tokens)})")
        print(f"  ãƒ‡ã‚³ãƒ¼ãƒ‰: {decoded}")

    print("\nâœ… Tokenizer test passed!")


def test_pipeline_basic():
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ§  Test 2: Pipeline Basic Functionality")
    print("=" * 60)

    # Config
    config = HFQBNNConfig(
        tokenizer_name='gpt2',
        embed_dim=128,
        num_heads=4,
        num_layers=2,
        hidden_dim=256,
        max_seq_len=128,
        use_qbnn_attention=True
    )

    # Pipeline
    pipeline = HFOpenAIQBNNPipeline(
        config=config,
        use_openai_embedding=False
    )

    # ãƒ†ã‚¹ãƒˆå…¥åŠ›
    test_text = "Quantum computing is"
    tokens = pipeline.tokenizer.encode(test_text, add_special_tokens=True)
    token_tensor = torch.tensor([tokens], dtype=torch.long)

    print(f"\n  å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: '{test_text}'")
    print(f"  ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(tokens)}")

    # Forward pass
    with torch.no_grad():
        logits = pipeline(token_tensor)

    print(f"  å‡ºåŠ›shape: {logits.shape}")
    print(f"  æœŸå¾…shape: (1, {len(tokens)}, {config.vocab_size})")

    assert logits.shape == (1, len(tokens), config.vocab_size), "Shape mismatch!"

    print("\nâœ… Pipeline basic test passed!")


def test_generation():
    """ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“ Test 3: Text Generation")
    print("=" * 60)

    # Small config for quick test
    config = HFQBNNConfig(
        tokenizer_name='gpt2',
        embed_dim=128,
        num_heads=4,
        num_layers=2,
        hidden_dim=256,
        max_seq_len=128,
        use_qbnn_attention=True
    )

    pipeline = HFOpenAIQBNNPipeline(config=config)

    prompts = [
        "The future of",
        "Quantum",
        "AI is"
    ]

    for prompt in prompts:
        output = pipeline.generate(
            prompt,
            max_length=10,
            temperature=1.0
        )
        print(f"\n  å…¥åŠ›: '{prompt}'")
        print(f"  å‡ºåŠ›: '{output}'")

    print("\nâœ… Generation test passed!")


def test_mini_training():
    """ãƒŸãƒ‹å­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“ Test 4: Mini Training")
    print("=" * 60)

    config = HFQBNNConfig(
        tokenizer_name='gpt2',
        embed_dim=64,
        num_heads=2,
        num_layers=1,
        hidden_dim=128,
        max_seq_len=64,
        use_qbnn_attention=False  # Faster for testing
    )

    pipeline = HFOpenAIQBNNPipeline(config=config)

    # Minimal training data
    texts = [
        "The quick brown fox jumps over the lazy dog.",
        "Quantum computers use quantum mechanics.",
        "Deep learning is a subset of machine learning.",
    ] * 5

    print(f"\n  å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {len(texts)} samples")
    print(f"  ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {pipeline.num_params:,}")

    # Quick training
    pipeline.train_model(
        texts,
        epochs=3,
        batch_size=2,
        lr=1e-3,
        seq_length=32
    )

    # Test generation after training
    output = pipeline.generate("The", max_length=15, temperature=0.8)
    print(f"\n  å­¦ç¿’å¾Œã®ç”Ÿæˆ: '{output}'")

    print("\nâœ… Mini training test passed!")


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
    print("=" * 70)
    print("ğŸ§ª HF-OpenAI-QBNN Pipeline - Basic Tests")
    print("=" * 70)

    try:
        # Test 1: Tokenizer
        test_tokenizer()

        # Test 2: Pipeline Basic
        test_pipeline_basic()

        # Test 3: Generation
        test_generation()

        # Test 4: Mini Training
        test_mini_training()

        print("\n" + "=" * 70)
        print("âœ… All tests passed!")
        print("=" * 70)

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == '__main__':
    exit(main())
