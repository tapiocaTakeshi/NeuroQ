#!/usr/bin/env python3
"""
æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Test script for Japanese text generation improvements
"""

import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from neuroquantum_layered import NeuroQuantumAI
    print("âœ… Successfully imported NeuroQuantumAI")
except ImportError as e:
    print(f"âŒ Failed to import NeuroQuantumAI: {e}")
    sys.exit(1)


def test_japanese_generation():
    """æ—¥æœ¬èªç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    # ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    test_prompts = [
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«ã¤ã„ã¦æ•™ãˆã¦",
        "äººå·¥çŸ¥èƒ½ã¨ã¯",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä»•çµ„ã¿",
    ]

    try:
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
        print("\nğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        model = NeuroQuantumAI(
            embed_dim=256,
            hidden_dim=512,
            num_heads=8,
            num_layers=6,
            max_seq_len=256,
            dropout=0.1,
            lambda_entangle=0.5,
        )

        # ç°¡æ˜“å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«ã¯æ¯å›åˆæœŸåŒ–ï¼‰
        print("âš ï¸ ç°¡æ˜“å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        # ç°¡æ˜“å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        sample_data = [
            "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€é‡å­åŠ›å­¦ã®åŸç†ã‚’åˆ©ç”¨ã—ãŸæ¬¡ä¸–ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã™ã€‚",
            "äººå·¥çŸ¥èƒ½ã¯äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡å€£ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚",
            "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€äººé–“ã®è„³ã®ç¥çµŒç´°èƒã®åƒãã‚’æ¨¡å€£ã—ãŸè¨ˆç®—ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚",
            "æ©Ÿæ¢°å­¦ç¿’ã¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹AIã®æ‰‹æ³•ã§ã™ã€‚",
        ] * 5
        model.train(sample_data, epochs=3)

        print("âœ… ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\n")

        # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ†ã‚¹ãƒˆ
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\n{'â”€' * 70}")
            print(f"ğŸ“ ãƒ†ã‚¹ãƒˆ {i}/{len(test_prompts)}")
            print(f"{'â”€' * 70}")
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
            print()

            # æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”Ÿæˆ
            print("ğŸ”„ ç”Ÿæˆä¸­ï¼ˆæ”¹å–„ç‰ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰...")
            result = model.generate(
                prompt=prompt,
                max_length=100,
                temp_min=0.5,           # ã‚ˆã‚Šä¿å®ˆçš„ãªæ¸©åº¦
                temp_max=0.8,
                top_k=40,
                top_p=0.9,
                repetition_penalty=2.0,  # å¼·åŠ›ãªç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£
                no_repeat_ngram_size=3,  # 3-gramã®ç¹°ã‚Šè¿”ã—é˜²æ­¢
            )

            print("ç”Ÿæˆçµæœ:")
            print("â”€" * 70)
            print(result)
            print("â”€" * 70)

            # ç¹°ã‚Šè¿”ã—ãƒã‚§ãƒƒã‚¯
            words = result.split()
            if len(words) > 0:
                word_counts = {}
                for word in words:
                    word_counts[word] = word_counts.get(word, 0) + 1

                repeated_words = [(word, count) for word, count in word_counts.items() if count > 3]
                if repeated_words:
                    print(f"\nâš ï¸ ç¹°ã‚Šè¿”ã—ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
                    for word, count in repeated_words:
                        print(f"   '{word}': {count}å›")
                else:
                    print(f"\nâœ… éåº¦ãªç¹°ã‚Šè¿”ã—ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

        print("\n" + "=" * 70)
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("=" * 70)

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

    return True


if __name__ == "__main__":
    success = test_japanese_generation()
    sys.exit(0 if success else 1)
