#!/usr/bin/env python3
"""
OpenAssistant/oasst1 ã§APQBç”ŸæˆAIã‚’å­¦ç¿’ãƒ»ãƒ†ã‚¹ãƒˆ
"""

import sys
sys.path.insert(0, '/Users/yuyahiguchi/Program/Qubit')

from apqb_generative_ai_v2 import (
    APQBGenerativeAI, 
    load_openassistant_data,
    SubwordTokenizer,
    CharTokenizer
)

def main():
    print("=" * 70)
    print("ğŸ§ âš›ï¸ APQB Generative AI - OpenAssistant/oasst1 å­¦ç¿’")
    print("=" * 70)
    
    # OpenAssistantãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆå°‘ãªã‚ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã§é«˜é€ŸåŒ–ï¼‰
    print("\nğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ä¸­...")
    training_text = load_openassistant_data(max_samples=1000, lang='all')
    
    if training_text is None:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å¤±æ•—")
        return
    
    print(f"ğŸ“Š å­¦ç¿’ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚º: {len(training_text):,} æ–‡å­—")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆã¨å­¦ç¿’
    print("\nğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
    ai = APQBGenerativeAI(
        embed_dim=96,       # å°‘ã—å°ã•ã‚ã§é«˜é€ŸåŒ–
        num_heads=6,
        num_layers=3,
        dropout_r=-0.3,
        max_vocab_size=2000,
        use_subword=True
    )
    
    print("\nğŸ“š å­¦ç¿’é–‹å§‹...")
    losses = ai.train(
        training_text,
        epochs=25,          # é«˜é€ŸåŒ–ã®ãŸã‚å°‘ãªã‚
        batch_size=24,
        seq_len=96
    )
    
    # çµ±è¨ˆæƒ…å ±
    stats = ai.get_stats()
    print(f"\nğŸ“ˆ ãƒ¢ãƒ‡ãƒ«çµ±è¨ˆ:")
    print(f"   èªå½™ã‚µã‚¤ã‚º: {stats['vocab_size']:,} ãƒˆãƒ¼ã‚¯ãƒ³")
    print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {stats['total_params']:,}")
    
    # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ
    prompts = [
        "Hello",
        "How can I",
        "The best way to",
        "Programming is",
        "AI will"
    ]
    
    print("\n" + "=" * 70)
    print("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆçµæœ")
    print("=" * 70)
    
    for prompt in prompts:
        print(f"\nğŸ”® ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ã€Œ{prompt}ã€")
        print("-" * 50)
        
        text = ai.generate(
            prompt, 
            max_length=100, 
            temperature=0.8, 
            top_k=40,
            quantum_sampling=True
        )
        print(f"{text}")
    
    # é‡å­ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”è¼ƒ
    print("\n" + "=" * 70)
    print("âš›ï¸ é‡å­ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° vs é€šå¸¸ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
    print("=" * 70)
    
    test_prompt = "The future"
    
    print(f"\nãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: ã€Œ{test_prompt}ã€")
    print("\n[é‡å­ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ON]")
    for i in range(3):
        text = ai.generate(test_prompt, max_length=60, temperature=0.9, quantum_sampling=True)
        print(f"  {i+1}. {text}")
    
    print("\n[é‡å­ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° OFF]")
    for i in range(3):
        text = ai.generate(test_prompt, max_length=60, temperature=0.9, quantum_sampling=False)
        print(f"  {i+1}. {text}")
    
    print("\nâœ… å®Œäº†ï¼")
    
    return ai


if __name__ == "__main__":
    main()

