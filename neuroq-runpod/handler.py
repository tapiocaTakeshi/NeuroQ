#!/usr/bin/env python3
"""
NeuroQ RunPod Serverless API Handler
=====================================
Common Crawlã‹ã‚‰äº‹å‰å­¦ç¿’ã™ã‚‹RunPod Serverless APIãƒãƒ³ãƒ‰ãƒ©ãƒ¼
"""

import runpod
import torch
import requests
import re
import os
from typing import Dict, Any, List
from io import BytesIO

# Common Crawlç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    from warcio.archiveiterator import ArchiveIterator
    from bs4 import BeautifulSoup
    COMMON_CRAWL_AVAILABLE = True
except ImportError:
    COMMON_CRAWL_AVAILABLE = False
    print("âš ï¸ warcio/beautifulsoup4 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# NeuroQuantumãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from neuroquantum_layered import NeuroQuantumAI, NeuroQuantumConfig
    LAYERED_AVAILABLE = True
except ImportError:
    LAYERED_AVAILABLE = False
    print("âš ï¸ neuroquantum_layered.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

try:
    from neuroquantum_brain import NeuroQuantumBrainAI
    BRAIN_AVAILABLE = True
except ImportError:
    BRAIN_AVAILABLE = False
    print("âš ï¸ neuroquantum_brain.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
layered_ai = None
brain_ai = None
is_pretrained = False


def fetch_common_crawl_data(max_records: int = 100, language: str = "ja") -> List[str]:
    """
    Common Crawlã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        max_records: å–å¾—ã™ã‚‹æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
        language: è¨€èªãƒ•ã‚£ãƒ«ã‚¿ ("ja" for Japanese)
    
    Returns:
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    if not COMMON_CRAWL_AVAILABLE:
        print("âš ï¸ Common Crawlãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return []
    
    texts = []
    
    # Common Crawl ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹API
    # æ—¥æœ¬èªã‚µã‚¤ãƒˆã‚’æ¤œç´¢
    index_url = "https://index.commoncrawl.org/CC-MAIN-2024-10-index"
    
    try:
        # æ—¥æœ¬èªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æ¤œç´¢
        search_url = f"{index_url}?url=*.jp/*&output=json&limit={max_records}"
        print(f"ğŸ”„ Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... (æœ€å¤§{max_records}ä»¶)")
        
        response = requests.get(search_url, timeout=30)
        if response.status_code != 200:
            print(f"âš ï¸ Common Crawl API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            return get_sample_training_data()
        
        lines = response.text.strip().split('\n')
        
        for i, line in enumerate(lines[:max_records]):
            try:
                import json
                record = json.loads(line)
                
                # WARCãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
                warc_url = f"https://data.commoncrawl.org/{record['filename']}"
                offset = int(record['offset'])
                length = int(record['length'])
                
                headers = {'Range': f'bytes={offset}-{offset+length-1}'}
                warc_response = requests.get(warc_url, headers=headers, timeout=30)
                
                if warc_response.status_code in [200, 206]:
                    # WARCãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
                    stream = BytesIO(warc_response.content)
                    for warc_record in ArchiveIterator(stream):
                        if warc_record.rec_type == 'response':
                            content = warc_record.content_stream().read()
                            # HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                            soup = BeautifulSoup(content, 'html.parser')
                            
                            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‰Šé™¤
                            for script in soup(["script", "style"]):
                                script.decompose()
                            
                            text = soup.get_text(separator=' ', strip=True)
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                            text = re.sub(r'\s+', ' ', text)
                            
                            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                            if language == "ja" and re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', text):
                                if len(text) > 100:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                                    texts.append(text[:2000])  # æœ€å¤§2000æ–‡å­—
                                    print(f"  âœ… {i+1}/{max_records}: {len(text)}æ–‡å­—å–å¾—")
                            elif language != "ja" and len(text) > 100:
                                texts.append(text[:2000])
                                print(f"  âœ… {i+1}/{max_records}: {len(text)}æ–‡å­—å–å¾—")
                
            except Exception as e:
                print(f"  âš ï¸ ãƒ¬ã‚³ãƒ¼ãƒ‰ {i+1} ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"âœ… Common Crawlã‹ã‚‰{len(texts)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—")
        
    except Exception as e:
        print(f"âš ï¸ Common Crawlå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        return get_sample_training_data()
    
    if not texts:
        return get_sample_training_data()
    
    return texts


def get_sample_training_data() -> List[str]:
    """ã‚µãƒ³ãƒ—ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
    return [
        "äººå·¥çŸ¥èƒ½ã¯ã€äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡å€£ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã‚„ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬ã‚„åˆ¤æ–­ã‚’è¡Œã„ã¾ã™ã€‚",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€é‡å­åŠ›å­¦ã®åŸç†ã‚’åˆ©ç”¨ã—ãŸæ¬¡ä¸–ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã™ã€‚å¾“æ¥ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã¯è§£ã‘ãªã„è¤‡é›‘ãªå•é¡Œã‚’é«˜é€Ÿã«è§£ãã“ã¨ãŒã§ãã¾ã™ã€‚",
        "è‡ªç„¶è¨€èªå‡¦ç†ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒäººé–“ã®è¨€èªã‚’ç†è§£ã—ã€ç”Ÿæˆã™ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã™ã€‚ç¿»è¨³ã€è¦ç´„ã€è³ªå•å¿œç­”ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€äººé–“ã®è„³ã®ç¥çµŒç´°èƒã®åƒãã‚’æ¨¡å€£ã—ãŸè¨ˆç®—ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å±¤çŠ¶ã«æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã§æ§‹æˆã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´ã‚’å­¦ç¿’ã—ã¾ã™ã€‚",
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«æŒ‡ç¤ºã‚’ä¸ãˆã‚‹ãŸã‚ã®è¨€èªã‚’ä½¿ã£ã¦ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ä½œæˆã™ã‚‹æŠ€è¡“ã§ã™ã€‚Pythonã€JavaScriptã€Javaãªã©å¤šãã®è¨€èªãŒã‚ã‚Šã¾ã™ã€‚",
        "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ‰ç”¨ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã€ãƒ“ã‚¸ãƒã‚¹ã‚„ç ”ç©¶ã«æ´»ç”¨ã™ã‚‹å­¦å•åˆ†é‡ã§ã™ã€‚çµ±è¨ˆå­¦ã€æ©Ÿæ¢°å­¦ç¿’ã€å¯è¦–åŒ–ãªã©ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚",
        "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆçµŒç”±ã§ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚AWSã€Azureã€GCPãªã©ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒä»£è¡¨çš„ã§ã™ã€‚",
        "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã¯ã€åˆ†æ•£å‹å°å¸³æŠ€è¡“ã®ä¸€ç¨®ã§ã€ãƒ‡ãƒ¼ã‚¿ã®æ”¹ã–ã‚“ã‚’é˜²ãä»•çµ„ã¿ã‚’æŒã£ã¦ã„ã¾ã™ã€‚æš—å·é€šè²¨ã‚„å¥‘ç´„ç®¡ç†ãªã©ã«å¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚",
    ]


def get_extended_training_data() -> List[str]:
    """æ‹¡å¼µã‚µãƒ³ãƒ—ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆå¯¾è©±å½¢å¼ã‚’å«ã‚€ï¼‰"""
    # åŸºæœ¬çš„ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    base_data = get_sample_training_data()
    
    # å¯¾è©±å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    dialogues = [
        "<USER>ã“ã‚“ã«ã¡ã¯<ASSISTANT>ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ­Qã§ã™ã€‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
        "<USER>ã‚ãªãŸã¯èª°ã§ã™ã‹<ASSISTANT>ç§ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ­Qã¨ã„ã†åå‰ã®ç”ŸæˆAIã§ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚",
        "<USER>é‡å­ã¨ã¯ä½•ã§ã™ã‹<ASSISTANT>é‡å­ã¨ã¯ã€ç‰©è³ªã‚„ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®æœ€å°å˜ä½ã®ã“ã¨ã§ã™ã€‚é‡å­åŠ›å­¦ã§ã¯ã€ç²’å­ã¯æ³¢ã®æ€§è³ªã‚‚æŒã¡ã¾ã™ã€‚",
        "<USER>AIã¨ã¯ä½•ã§ã™ã‹<ASSISTANT>AIã¯äººå·¥çŸ¥èƒ½ï¼ˆArtificial Intelligenceï¼‰ã®ç•¥ã§ã€æ©Ÿæ¢°ã«çŸ¥çš„ãªæŒ¯ã‚‹èˆã„ã‚’ã•ã›ã‚‹æŠ€è¡“ã§ã™ã€‚",
        "<USER>Hello<ASSISTANT>Hello! I'm NeuroQ. How can I help you today?",
        "<USER>What is quantum computing<ASSISTANT>Quantum computing uses quantum mechanics principles to perform calculations much faster than classical computers.",
        "<USER>ã‚ã‚ŠãŒã¨ã†<ASSISTANT>ã©ã†ã„ãŸã—ã¾ã—ã¦ï¼ãŠå½¹ã«ç«‹ã¦ã¦å¬‰ã—ã„ã§ã™ã€‚",
        "<USER>æ•™ãˆã¦ãã ã•ã„<ASSISTANT>ã¯ã„ã€ä½•ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿå…·ä½“çš„ã«æ•™ãˆã¦ãã ã•ã„ã€‚",
    ]
    
    # ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    all_data = base_data + dialogues
    
    return all_data


def pretrain_model(model, max_records: int = 50, epochs: int = 5):
    """
    Common Crawlã‹ã‚‰äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œ
    
    Returns:
        bool: å­¦ç¿’ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    global is_pretrained
    
    print(f"ğŸ” pretrain_modelé–‹å§‹: is_pretrained={is_pretrained}, model.model is None={model.model is None if model else 'N/A'}")
    
    # æ—¢ã«ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ç¢ºèª
    if is_pretrained and model.model is not None:
        print("â„¹ï¸ æ—¢ã«äº‹å‰å­¦ç¿’æ¸ˆã¿ã§ã™")
        return True
    
    print("ğŸ”„ äº‹å‰å­¦ç¿’ã‚’é–‹å§‹...")
    print(f"   ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    print(f"   ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼å­˜åœ¨: {os.path.exists('neuroq_tokenizer.model')}")
    
    # æ‹¡å¼µã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆå¯¾è©±å½¢å¼ã‚’å«ã‚€ï¼‰
    training_data = get_extended_training_data()
    
    # Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦ã¿ã‚‹ï¼ˆè¿½åŠ ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ï¼‰
    try:
        cc_data = fetch_common_crawl_data(max_records=max_records)
        if cc_data:
            training_data.extend(cc_data)
            print(f"ğŸ“¡ Common Crawlã‹ã‚‰{len(cc_data)}ä»¶è¿½åŠ ")
    except Exception as e:
        print(f"âš ï¸ Common Crawlå–å¾—ã‚¹ã‚­ãƒƒãƒ—: {e}")
    
    if training_data:
        # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆã‚·ãƒ¼ã‚±ãƒ³ã‚¹ä½œæˆã®ãŸã‚ï¼‰
        # ååˆ†ãªé•·ã•ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ç¹°ã‚Šè¿”ã—å›æ•°ã‚’å¢—ã‚„ã™
        long_text = " ".join(training_data) * 5
        combined_data = [long_text]
        print(f"ğŸ“š çµåˆå¾Œãƒ†ã‚­ã‚¹ãƒˆé•·: {len(long_text)} ã§å­¦ç¿’é–‹å§‹ (ã‚¨ãƒãƒƒã‚¯: {epochs})")
        
        # è¤‡æ•°å›ã®è©¦è¡Œã§å­¦ç¿’ã‚’å®Ÿè¡Œ
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ å­¦ç¿’è©¦è¡Œ {attempt + 1}/{max_retries}...")
                # train ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ï¼ˆseq_lenã‚’çŸ­ãè¨­å®šï¼‰
                model.train(combined_data, epochs=epochs, seq_len=16)
                
                # å­¦ç¿’å¾Œã®ç¢ºèª
                if model.model is None:
                    print(f"âš ï¸ å­¦ç¿’è©¦è¡Œ {attempt + 1} å¾Œã‚‚model.modelãŒNoneã§ã™")
                    if attempt < max_retries - 1:
                        print("   å†è©¦è¡Œã—ã¾ã™...")
                        continue
                    else:
                        print("   ã™ã¹ã¦ã®è©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸ")
                        raise Exception("model.model is None after all training attempts")
                
                is_pretrained = True
                print(f"âœ… äº‹å‰å­¦ç¿’å®Œäº† (è©¦è¡Œ {attempt + 1}, model.model is None: {model.model is None})")
                return True
            except Exception as e:
                print(f"âš ï¸ å­¦ç¿’è©¦è¡Œ {attempt + 1} ã‚¨ãƒ©ãƒ¼: {e}")
                import traceback
                traceback.print_exc()
                
                if attempt < max_retries - 1:
                    print("   å†è©¦è¡Œã—ã¾ã™...")
                    continue
                else:
                    print("   ã™ã¹ã¦ã®è©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸã€‚æœ€å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å†è©¦è¡Œã—ã¾ã™...")
            
            # æœ€å°é™ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å†è©¦è¡Œ
            try:
                minimal_text = """
                äººå·¥çŸ¥èƒ½ã¯ã€äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡å€£ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚
                é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€é‡å­åŠ›å­¦ã®åŸç†ã‚’åˆ©ç”¨ã—ãŸæ¬¡ä¸–ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã™ã€‚
                è‡ªç„¶è¨€èªå‡¦ç†ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒäººé–“ã®è¨€èªã‚’ç†è§£ã—ç”Ÿæˆã™ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã™ã€‚
                ã“ã‚“ã«ã¡ã¯ã€‚ç§ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ­Qã§ã™ã€‚ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ
                ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€å¤šå±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®æ‰‹æ³•ã§ã™ã€‚
                <USER>ã“ã‚“ã«ã¡ã¯<ASSISTANT>ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ­Qã§ã™ã€‚
                <USER>é‡å­ã¨ã¯<ASSISTANT>é‡å­ã¯ç‰©è³ªã‚„ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®æœ€å°å˜ä½ã§ã™ã€‚
                <USER>Hello<ASSISTANT>Hello! I'm NeuroQ. How can I help you?
                """ * 20
                print("ğŸ”„ æœ€å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                model.train([minimal_text], epochs=5, seq_len=16)
                
                # å­¦ç¿’å¾Œã®ç¢ºèª
                if model.model is None:
                    print("âš ï¸ æœ€å°ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’å¾Œã‚‚model.modelãŒNoneã§ã™")
                    return False
                
                is_pretrained = True
                print(f"âœ… æœ€å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’å®Œäº† (model.model is None: {model.model is None})")
                return True
            except Exception as e2:
                print(f"âš ï¸ æœ€å°ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’ã‚‚å¤±æ•—: {e2}")
                import traceback
                traceback.print_exc()
                return False
    else:
        print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return False


def get_layered_model(pretrain: bool = True):
    """
    Layeredãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆäº‹å‰å­¦ç¿’ä»˜ãï¼‰
    
    Returns:
        tuple: (model, is_trained) - ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹
    """
    global layered_ai
    trained = False
    
    if layered_ai is None and LAYERED_AVAILABLE:
        print("ğŸ”„ Layeredãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        layered_ai = NeuroQuantumAI()
        print("âœ… Layeredãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        
        if pretrain:
            trained = pretrain_model(layered_ai)
    elif layered_ai is not None:
        # æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã€å­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ç¢ºèª
        trained = layered_ai.model is not None
        if not trained and pretrain:
            trained = pretrain_model(layered_ai)
    
    return layered_ai, trained


def get_brain_model(pretrain: bool = True):
    """
    Brainãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆäº‹å‰å­¦ç¿’ä»˜ãï¼‰
    
    Returns:
        tuple: (model, is_trained) - ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹
    """
    global brain_ai
    trained = False
    
    if brain_ai is None and BRAIN_AVAILABLE:
        print("ğŸ”„ Brainãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        brain_ai = NeuroQuantumBrainAI()
        print("âœ… Brainãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        
        if pretrain:
            trained = pretrain_model(brain_ai)
    elif brain_ai is not None:
        # æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆã€å­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ç¢ºèª
        trained = brain_ai.model is not None
        if not trained and pretrain:
            trained = pretrain_model(brain_ai)
    
    return brain_ai, trained


def handler(event: Dict[str, Any]) -> Dict[str, Any]:
    """
    RunPod Serverless ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹:
    {
        "input": {
            "action": "generate",
            "prompt": "ã“ã‚“ã«ã¡ã¯",
            "mode": "layered",
            "max_length": 100,
            "temp_min": 0.4,
            "temp_max": 0.8,
            "pretrain": true
        }
    }
    """
    global is_pretrained, layered_ai, brain_ai
    
    try:
        input_data = event.get("input", {})
        action = input_data.get("action", "generate")
        pretrain = input_data.get("pretrain", True)
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
        print(f"ğŸ“¥ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡: action={action}, pretrain={pretrain}")
        print(f"   is_pretrained={is_pretrained}")
        print(f"   layered_ai is None={layered_ai is None}")
        print(f"   layered_ai.model is None={layered_ai.model is None if layered_ai else 'N/A'}")
        
        # ========================================
        # æ¯å›ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦åˆæœŸåŒ–
        # ========================================
        if not is_pretrained or (layered_ai is not None and layered_ai.model is None) or (brain_ai is not None and brain_ai.model is None):
            print("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒæœªåˆæœŸåŒ–ã¾ãŸã¯æœªå­¦ç¿’ã§ã™ã€‚åˆæœŸåŒ–ã‚’å®Ÿè¡Œã—ã¾ã™...")
            print(f"   is_pretrained={is_pretrained}")
            print(f"   layered_ai is None={layered_ai is None}")
            print(f"   layered_ai.model is None={layered_ai.model is None if layered_ai else 'N/A'}")
            print(f"   brain_ai is None={brain_ai is None}")
            print(f"   brain_ai.model is None={brain_ai.model is None if brain_ai else 'N/A'}")
            initialize_models()
            
            # åˆæœŸåŒ–å¾Œã®ç¢ºèª
            if layered_ai is not None and layered_ai.model is None:
                print("âš ï¸ åˆæœŸåŒ–å¾Œã‚‚layered_ai.modelãŒNoneã§ã™ã€‚å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                retrained = pretrain_model(layered_ai, max_records=30, epochs=5)
                if retrained and layered_ai.model is not None:
                    is_pretrained = True
                    print("âœ… layered_aiã®å†å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        if action == "health":
            return {
                "status": "healthy",
                "layered_available": LAYERED_AVAILABLE,
                "brain_available": BRAIN_AVAILABLE,
                "common_crawl_available": COMMON_CRAWL_AVAILABLE,
                "cuda_available": torch.cuda.is_available(),
                "is_pretrained": is_pretrained
            }
        
        # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        if action == "generate":
            mode = input_data.get("mode", "layered")
            prompt = input_data.get("prompt", "")
            
            print(f"ğŸ¯ ç”Ÿæˆé–‹å§‹: mode={mode}, prompt='{prompt[:50]}...'")
            
            # ========================================
            # ç”Ÿæˆå‰ã®äº‹å‰å­¦ç¿’ç¢ºèªï¼ˆå¼·åˆ¶ï¼‰
            # ========================================
            print("ğŸ” ç”Ÿæˆå‰ã®ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
            
            if mode == "layered":
                if layered_ai is None or layered_ai.model is None:
                    print("âš ï¸ Layeredãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™...")
                    if layered_ai is None:
                        layered_ai = NeuroQuantumAI()
                    success = pretrain_model(layered_ai, max_records=30, epochs=5)
                    if not success or layered_ai.model is None:
                        return {
                            "status": "error",
                            "error": "äº‹å‰å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                        }
                    is_pretrained = True
                    print("âœ… ç”Ÿæˆå‰ã®äº‹å‰å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
                else:
                    print("âœ… Layeredãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ã§ã™")
                    
            elif mode == "brain":
                if brain_ai is None or brain_ai.model is None:
                    print("âš ï¸ Brainãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¾ã™...")
                    if brain_ai is None:
                        brain_ai = NeuroQuantumBrainAI()
                    success = pretrain_model(brain_ai, max_records=30, epochs=5)
                    if not success or brain_ai.model is None:
                        return {
                            "status": "error",
                            "error": "äº‹å‰å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                        }
                    is_pretrained = True
                    print("âœ… ç”Ÿæˆå‰ã®äº‹å‰å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
                else:
                    print("âœ… Brainãƒ¢ãƒ‡ãƒ«ã¯æ—¢ã«å­¦ç¿’æ¸ˆã¿ã§ã™")
            max_length = input_data.get("max_length", 100)
            
            # æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆå¾Œæ–¹äº’æ›æ€§å¯¾å¿œï¼‰
            # temperature ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€temp_min/temp_max ã«å¤‰æ›
            temperature = input_data.get("temperature", None)
            if temperature is not None:
                # temperature ã‚’ temp_min/temp_max ã®ç¯„å›²ã«å¤‰æ›
                temp_min = temperature * 0.8
                temp_max = temperature * 1.2
            else:
                temp_min = input_data.get("temp_min", 0.4)
                temp_max = input_data.get("temp_max", 0.8)
            
            top_k = input_data.get("top_k", 50)
            top_p = input_data.get("top_p", 0.9)
            
            if mode == "layered" and LAYERED_AVAILABLE:
                model, trained = get_layered_model(pretrain=pretrain)
                
                # ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if model is None:
                    return {
                        "status": "error",
                        "error": "ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"
                    }
                
                # äº‹å‰å­¦ç¿’ãŒå¤±æ•—ã—ãŸå ´åˆã€ã“ã“ã§å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                if model.model is None:
                    print("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                    print(f"   ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
                    print(f"   ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {os.path.exists('neuroq_tokenizer.model')}")
                    print(f"   /appå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«: {os.listdir('/app') if os.path.exists('/app') else 'N/A'}")
                    
                    # è¤‡æ•°å›ã®è©¦è¡Œã§å­¦ç¿’ã‚’å®Ÿè¡Œ
                    max_retries = 3
                    training_success = False
                    
                    for attempt in range(max_retries):
                        try:
                            print(f"ğŸ”„ å­¦ç¿’è©¦è¡Œ {attempt + 1}/{max_retries}...")
                            # æ‹¡å¼µã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆå¯¾è©±å½¢å¼ã‚’å«ã‚€ï¼‰
                            sample_data = get_extended_training_data()
                            # çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆã—ã¦é•·ãã™ã‚‹ï¼ˆååˆ†ãªé•·ã•ã‚’ç¢ºä¿ï¼‰
                            long_text = " ".join(sample_data) * 10
                            combined_data = [long_text]
                            print(f"   çµåˆå¾Œã®ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(long_text)}")
                            # seq_lenã‚’çŸ­ãè¨­å®šï¼ˆ16ï¼‰ã€ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã™
                            model.train(combined_data, epochs=5, seq_len=16)
                            print("âœ… ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’å®Œäº†")
                            print(f"   model.model is None: {model.model is None}")
                            
                            # å­¦ç¿’å¾Œã®ç¢ºèª
                            if model.model is None:
                                if attempt < max_retries - 1:
                                    print(f"   å­¦ç¿’è©¦è¡Œ {attempt + 1} å¾Œã‚‚model.modelãŒNoneã§ã™ã€‚å†è©¦è¡Œã—ã¾ã™...")
                                    continue
                                else:
                                    raise Exception("ã™ã¹ã¦ã®å­¦ç¿’è©¦è¡Œå¾Œã‚‚model.modelãŒNoneã§ã™")
                            
                            training_success = True
                            global is_pretrained
                            is_pretrained = True
                            break
                            
                        except Exception as train_error:
                            print(f"âš ï¸ å­¦ç¿’è©¦è¡Œ {attempt + 1} å¤±æ•—: {train_error}")
                            import traceback
                            traceback.print_exc()
                            
                            if attempt < max_retries - 1:
                                print("   å†è©¦è¡Œã—ã¾ã™...")
                                continue
                            else:
                                print("   ã™ã¹ã¦ã®å­¦ç¿’è©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸ")
                    
                    if not training_success or model.model is None:
                        return {
                            "status": "error",
                            "error": "ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã™ã¹ã¦ã®è©¦è¡ŒãŒå¤±æ•—ã—ã¾ã—ãŸã€‚"
                        }
                
                try:
                    # æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢å¼ (temp_min/temp_max)
                    result = model.generate(
                        prompt=prompt,
                        max_length=max_length,
                        temp_min=temp_min,
                        temp_max=temp_max,
                        top_k=top_k,
                        top_p=top_p
                    )
                except TypeError as e:
                    # å¾Œæ–¹äº’æ›æ€§: å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ temperature ã‚’ä½¿ç”¨
                    if "temp_min" in str(e) or "temp_max" in str(e):
                        avg_temp = (temp_min + temp_max) / 2
                        result = model.generate(
                            prompt=prompt,
                            max_length=max_length,
                            temperature=avg_temp,
                            top_k=top_k,
                            top_p=top_p
                        )
                    else:
                        raise e
                except ValueError as e:
                    # è‡ªå‹•å­¦ç¿’ã‚‚å¤±æ•—ã—ãŸå ´åˆã€å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                    error_msg = str(e)
                    print(f"âš ï¸ generate ValueError: {error_msg}")
                    
                    # ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã®å ´åˆã€å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                    if "ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“" in error_msg or "model.model is None" in error_msg or model.model is None:
                        print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã®ãŸã‚ã€å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                        try:
                            # æ‹¡å¼µã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆå¯¾è©±å½¢å¼ã‚’å«ã‚€ï¼‰
                            sample_data = get_extended_training_data()
                            long_text = " ".join(sample_data) * 10
                            combined_data = [long_text]
                            model.train(combined_data, epochs=5, seq_len=16)
                            
                            if model.model is None:
                                return {
                                    "status": "error",
                                    "error": "ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†å­¦ç¿’å¾Œã‚‚model.modelãŒNoneã§ã™ã€‚"
                                }
                            
                            global is_pretrained
                            is_pretrained = True
                            
                            # å†å­¦ç¿’å¾Œã€å†åº¦ç”Ÿæˆã‚’è©¦ã¿ã‚‹
                            print("âœ… å†å­¦ç¿’å®Œäº†ã€‚å†åº¦ç”Ÿæˆã‚’è©¦ã¿ã¾ã™...")
                            result = model.generate(
                                prompt=prompt,
                                max_length=max_length,
                                temp_min=temp_min,
                                temp_max=temp_max,
                                top_k=top_k,
                                top_p=top_p
                            )
                        except Exception as retry_error:
                            print(f"âš ï¸ å†å­¦ç¿’ã‚‚å¤±æ•—: {retry_error}")
                            import traceback
                            traceback.print_exc()
                            return {
                                "status": "error",
                                "error": f"ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(retry_error)}"
                            }
                    else:
                        return {
                            "status": "error",
                            "error": f"ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {error_msg}"
                        }
                except Exception as e:
                    # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                    error_msg = str(e)
                    print(f"âš ï¸ generate Exception: {error_msg}")
                    import traceback
                    traceback.print_exc()
                    return {
                        "status": "error",
                        "error": f"ç”Ÿæˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"
                    }
                
                # ç”ŸæˆçµæœãŒã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if result == "ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“" or not result:
                    return {
                        "status": "error",
                        "error": "ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    }
                
                return {
                    "status": "success",
                    "mode": "layered",
                    "prompt": prompt,
                    "generated_text": result,
                    "is_pretrained": is_pretrained
                }
            
            elif mode == "brain" and BRAIN_AVAILABLE:
                model, trained = get_brain_model(pretrain=pretrain)
                
                # ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’æ¸ˆã¿ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if model is None:
                    return {
                        "status": "error",
                        "error": "ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"
                    }
                
                # äº‹å‰å­¦ç¿’ãŒå¤±æ•—ã—ãŸå ´åˆã€ã“ã“ã§å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                if model.model is None:
                    print("âš ï¸ Brainãƒ¢ãƒ‡ãƒ«ãŒæœªå­¦ç¿’ã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                    try:
                        sample_data = get_sample_training_data()
                        model.train(sample_data, epochs=3)
                        print("âœ… Brainãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’å®Œäº†")
                    except Exception as train_error:
                        print(f"âš ï¸ Brainãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®å­¦ç¿’å¤±æ•—: {train_error}")
                        return {
                            "status": "error",
                            "error": f"Brainãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(train_error)}"
                        }
                
                try:
                    result = model.generate(
                        prompt=prompt,
                        max_length=max_length,
                        temperature_min=temp_min,
                        temperature_max=temp_max
                    )
                except ValueError as e:
                    # è‡ªå‹•å­¦ç¿’ã‚‚å¤±æ•—ã—ãŸå ´åˆ
                    error_msg = str(e)
                    print(f"âš ï¸ Brain generate ValueError: {error_msg}")
                    return {
                        "status": "error",
                        "error": f"Brainãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {error_msg}"
                    }
                except Exception as e:
                    # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
                    error_msg = str(e)
                    print(f"âš ï¸ Brain generate Exception: {error_msg}")
                    import traceback
                    traceback.print_exc()
                    return {
                        "status": "error",
                        "error": f"Brainç”Ÿæˆæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_msg}"
                    }
                
                # ç”ŸæˆçµæœãŒã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã©ã†ã‹ã‚’ç¢ºèª
                if result == "ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“" or not result:
                    return {
                        "status": "error",
                        "error": "ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å­¦ç¿’ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    }
                
                return {
                    "status": "success",
                    "mode": "brain",
                    "prompt": prompt,
                    "generated_text": result,
                    "is_pretrained": is_pretrained
                }
            
            else:
                return {
                    "status": "error",
                    "error": f"ãƒ¢ãƒ¼ãƒ‰ '{mode}' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"
                }
        
        # è¿½åŠ å­¦ç¿’
        if action == "train":
            mode = input_data.get("mode", "layered")
            training_data = input_data.get("training_data", [])
            epochs = input_data.get("epochs", 10)
            use_common_crawl = input_data.get("use_common_crawl", False)
            max_records = input_data.get("max_records", 50)
            
            # Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            if use_common_crawl:
                cc_data = fetch_common_crawl_data(max_records=max_records)
                training_data.extend(cc_data)
            
            # training_dataãŒç©ºã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            if not training_data:
                print("âš ï¸ training_data ãŒç©ºã§ã™ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                training_data = get_sample_training_data()
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            long_text = " ".join(training_data) * 3
            combined_data = [long_text]
            print(f"ğŸ“š çµåˆå¾Œãƒ†ã‚­ã‚¹ãƒˆé•·: {len(long_text)}")
            
            if mode == "layered" and LAYERED_AVAILABLE:
                model, _ = get_layered_model(pretrain=False)
                if model is None:
                    return {"status": "error", "error": "ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"}
                
                try:
                    model.train(combined_data, epochs=epochs, seq_len=16)
                    is_pretrained = True
                    return {
                        "status": "success",
                        "mode": "layered",
                        "message": f"{len(training_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§{epochs}ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†"
                    }
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    return {"status": "error", "error": f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}"}
            
            elif mode == "brain" and BRAIN_AVAILABLE:
                model, _ = get_brain_model(pretrain=False)
                if model is None:
                    return {"status": "error", "error": "ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"}
                
                try:
                    model.train(combined_data, epochs=epochs, seq_len=16)
                    is_pretrained = True
                    return {
                        "status": "success",
                        "mode": "brain",
                        "message": f"{len(training_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§{epochs}ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†"
                    }
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    return {"status": "error", "error": f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {str(e)}"}
            
            else:
                return {"status": "error", "error": f"ãƒ¢ãƒ¼ãƒ‰ '{mode}' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"}
        
        return {"status": "error", "error": f"ä¸æ˜ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}"}
    
    except Exception as e:
        import traceback
        error_msg = str(e)
        print(f"âš ï¸ Handler Exception: {error_msg}")
        traceback.print_exc()
        return {"status": "error", "error": f"ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚¨ãƒ©ãƒ¼: {error_msg}"}


# èµ·å‹•æ™‚ã«äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œ
def initialize_models():
    """
    èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã€äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œ
    ã“ã‚Œã«ã‚ˆã‚Šã€æœ€åˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã®é…å»¶ã‚’å›é¿
    """
    global is_pretrained
    
    print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã¨äº‹å‰å­¦ç¿’ã‚’é–‹å§‹...")
    print(f"   ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
    print(f"   /appå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«: {os.listdir('/app') if os.path.exists('/app') else 'N/A'}")
    print(f"   ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼å­˜åœ¨: {os.path.exists('neuroq_tokenizer.model')}")
    print(f"   /app/ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼å­˜åœ¨: {os.path.exists('/app/neuroq_tokenizer.model')}")
    
    # Layeredãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ãƒ»å­¦ç¿’
    if LAYERED_AVAILABLE:
        try:
            model, trained = get_layered_model(pretrain=True)
            if trained and model is not None and model.model is not None:
                print("âœ… Layeredãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
                is_pretrained = True
            else:
                print(f"âš ï¸ Layeredãƒ¢ãƒ‡ãƒ«: trained={trained}, model is None={model is None}, model.model is None={model.model is None if model else 'N/A'}")
                # å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                if model is not None and model.model is None:
                    print("ğŸ”„ Layeredãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                    retrained = pretrain_model(model, max_records=30, epochs=5)
                    if retrained and model.model is not None:
                        print("âœ… Layeredãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
                        is_pretrained = True
        except Exception as e:
            print(f"âš ï¸ Layeredãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    # Brainãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ãƒ»å­¦ç¿’
    if BRAIN_AVAILABLE:
        try:
            model, trained = get_brain_model(pretrain=True)
            if trained and model is not None and model.model is not None:
                print("âœ… Brainãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                print(f"âš ï¸ Brainãƒ¢ãƒ‡ãƒ«: trained={trained}, model is None={model is None}, model.model is None={model.model is None if model else 'N/A'}")
                # å†åº¦å­¦ç¿’ã‚’è©¦ã¿ã‚‹
                if model is not None and model.model is None:
                    print("ğŸ”„ Brainãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã‚’è©¦ã¿ã¾ã™...")
                    retrained = pretrain_model(model, max_records=30, epochs=5)
                    if retrained and model.model is not None:
                        print("âœ… Brainãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âš ï¸ Brainãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"ğŸ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº† (is_pretrained: {is_pretrained})")


# ========================================
# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æ™‚ã«åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
# ========================================
# RunPod Serverlessã§ã¯__main__ãŒå®Ÿè¡Œã•ã‚Œãªã„å ´åˆãŒã‚ã‚‹ãŸã‚ã€
# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã§åˆæœŸåŒ–ã‚’è¡Œã†

# ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’/appã«å¤‰æ›´ï¼ˆãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‹ã‚ˆã†ã«ï¼‰
if os.path.exists('/app'):
    os.chdir('/app')
    print(f"ğŸ“ ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ /app ã«å¤‰æ›´ã—ã¾ã—ãŸ")

print("ğŸš€ NeuroQ RunPod Serverless Handler ã‚’èµ·å‹•ã—ã¾ã™...")
print(f"   Common Crawl: {'âœ…' if COMMON_CRAWL_AVAILABLE else 'âŒ'}")
print(f"   Layered: {'âœ…' if LAYERED_AVAILABLE else 'âŒ'}")
print(f"   Brain: {'âœ…' if BRAIN_AVAILABLE else 'âŒ'}")

# èµ·å‹•æ™‚ã«äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œï¼ˆé‡è¦ï¼ï¼‰
initialize_models()

# RunPod Serverless èµ·å‹•
runpod.serverless.start({"handler": handler})
