#!/usr/bin/env python3
"""
NeuroQ RunPod Serverless API Handler
=====================================
Common Crawlã‹ã‚‰äº‹å‰å­¦ç¿’ã™ã‚‹RunPod Serverless APIãƒãƒ³ãƒ‰ãƒ©ãƒ¼
"""

import runpod
import torch
import requests
import re
from typing import Dict, Any, List
from io import BytesIO

# Common Crawlç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    from warcio.archiveiterator import ArchiveIterator
    from bs4 import BeautifulSoup
    COMMON_CRAWL_AVAILABLE = True
except ImportError:
    COMMON_CRAWL_AVAILABLE = False
    print("âš ï¸ warcio/beautifulsoup4 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# NeuroQuantumãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from neuroquantum_layered import NeuroQuantumAI, NeuroQuantumConfig
    LAYERED_AVAILABLE = True
except ImportError:
    LAYERED_AVAILABLE = False
    print("âš ï¸ neuroquantum_layered.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

try:
    from neuroquantum_brain import NeuroQuantumBrainAI
    BRAIN_AVAILABLE = True
except ImportError:
    BRAIN_AVAILABLE = False
    print("âš ï¸ neuroquantum_brain.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
layered_ai = None
brain_ai = None
is_pretrained = False


def fetch_common_crawl_data(max_records: int = 100, language: str = "ja") -> List[str]:
    """
    Common Crawlã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Args:
        max_records: å–å¾—ã™ã‚‹æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
        language: è¨€èªãƒ•ã‚£ãƒ«ã‚¿ ("ja" for Japanese)
    
    Returns:
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    if not COMMON_CRAWL_AVAILABLE:
        print("âš ï¸ Common Crawlãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return []
    
    texts = []
    
    # Common Crawl ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹API
    # æ—¥æœ¬èªã‚µã‚¤ãƒˆã‚’æ¤œç´¢
    index_url = "https://index.commoncrawl.org/CC-MAIN-2024-10-index"
    
    try:
        # æ—¥æœ¬èªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’æ¤œç´¢
        search_url = f"{index_url}?url=*.jp/*&output=json&limit={max_records}"
        print(f"ğŸ”„ Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... (æœ€å¤§{max_records}ä»¶)")
        
        response = requests.get(search_url, timeout=30)
        if response.status_code != 200:
            print(f"âš ï¸ Common Crawl API ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            return get_sample_training_data()
        
        lines = response.text.strip().split('\n')
        
        for i, line in enumerate(lines[:max_records]):
            try:
                import json
                record = json.loads(line)
                
                # WARCãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
                warc_url = f"https://data.commoncrawl.org/{record['filename']}"
                offset = int(record['offset'])
                length = int(record['length'])
                
                headers = {'Range': f'bytes={offset}-{offset+length-1}'}
                warc_response = requests.get(warc_url, headers=headers, timeout=30)
                
                if warc_response.status_code in [200, 206]:
                    # WARCãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
                    stream = BytesIO(warc_response.content)
                    for warc_record in ArchiveIterator(stream):
                        if warc_record.rec_type == 'response':
                            content = warc_record.content_stream().read()
                            # HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                            soup = BeautifulSoup(content, 'html.parser')
                            
                            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å‰Šé™¤
                            for script in soup(["script", "style"]):
                                script.decompose()
                            
                            text = soup.get_text(separator=' ', strip=True)
                            
                            # ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                            text = re.sub(r'\s+', ' ', text)
                            
                            # æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                            if language == "ja" and re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]', text):
                                if len(text) > 100:  # çŸ­ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã¯é™¤å¤–
                                    texts.append(text[:2000])  # æœ€å¤§2000æ–‡å­—
                                    print(f"  âœ… {i+1}/{max_records}: {len(text)}æ–‡å­—å–å¾—")
                            elif language != "ja" and len(text) > 100:
                                texts.append(text[:2000])
                                print(f"  âœ… {i+1}/{max_records}: {len(text)}æ–‡å­—å–å¾—")
                
            except Exception as e:
                print(f"  âš ï¸ ãƒ¬ã‚³ãƒ¼ãƒ‰ {i+1} ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        print(f"âœ… Common Crawlã‹ã‚‰{len(texts)}ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—")
        
    except Exception as e:
        print(f"âš ï¸ Common Crawlå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        return get_sample_training_data()
    
    if not texts:
        return get_sample_training_data()
    
    return texts


def get_sample_training_data() -> List[str]:
    """ã‚µãƒ³ãƒ—ãƒ«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
    return [
        "äººå·¥çŸ¥èƒ½ã¯ã€äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡å€£ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æ©Ÿæ¢°å­¦ç¿’ã‚„ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬ã‚„åˆ¤æ–­ã‚’è¡Œã„ã¾ã™ã€‚",
        "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ã€é‡å­åŠ›å­¦ã®åŸç†ã‚’åˆ©ç”¨ã—ãŸæ¬¡ä¸–ä»£ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã™ã€‚å¾“æ¥ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã¯è§£ã‘ãªã„è¤‡é›‘ãªå•é¡Œã‚’é«˜é€Ÿã«è§£ãã“ã¨ãŒã§ãã¾ã™ã€‚",
        "è‡ªç„¶è¨€èªå‡¦ç†ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒäººé–“ã®è¨€èªã‚’ç†è§£ã—ã€ç”Ÿæˆã™ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã™ã€‚ç¿»è¨³ã€è¦ç´„ã€è³ªå•å¿œç­”ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€äººé–“ã®è„³ã®ç¥çµŒç´°èƒã®åƒãã‚’æ¨¡å€£ã—ãŸè¨ˆç®—ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å±¤çŠ¶ã«æ¥ç¶šã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã§æ§‹æˆã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´ã‚’å­¦ç¿’ã—ã¾ã™ã€‚",
        "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«æŒ‡ç¤ºã‚’ä¸ãˆã‚‹ãŸã‚ã®è¨€èªã‚’ä½¿ã£ã¦ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ä½œæˆã™ã‚‹æŠ€è¡“ã§ã™ã€‚Pythonã€JavaScriptã€Javaãªã©å¤šãã®è¨€èªãŒã‚ã‚Šã¾ã™ã€‚",
        "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ‰ç”¨ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã€ãƒ“ã‚¸ãƒã‚¹ã‚„ç ”ç©¶ã«æ´»ç”¨ã™ã‚‹å­¦å•åˆ†é‡ã§ã™ã€‚çµ±è¨ˆå­¦ã€æ©Ÿæ¢°å­¦ç¿’ã€å¯è¦–åŒ–ãªã©ã®æ‰‹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚",
        "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆçµŒç”±ã§ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚AWSã€Azureã€GCPãªã©ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒä»£è¡¨çš„ã§ã™ã€‚",
        "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³ã¯ã€åˆ†æ•£å‹å°å¸³æŠ€è¡“ã®ä¸€ç¨®ã§ã€ãƒ‡ãƒ¼ã‚¿ã®æ”¹ã–ã‚“ã‚’é˜²ãä»•çµ„ã¿ã‚’æŒã£ã¦ã„ã¾ã™ã€‚æš—å·é€šè²¨ã‚„å¥‘ç´„ç®¡ç†ãªã©ã«å¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚",
    ]


def pretrain_model(model, max_records: int = 50, epochs: int = 5):
    """
    Common Crawlã‹ã‚‰äº‹å‰å­¦ç¿’ã‚’å®Ÿè¡Œ
    """
    global is_pretrained
    
    if is_pretrained:
        print("â„¹ï¸ æ—¢ã«äº‹å‰å­¦ç¿’æ¸ˆã¿ã§ã™")
        return
    
    print("ğŸ”„ äº‹å‰å­¦ç¿’ã‚’é–‹å§‹...")
    
    # Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    training_data = fetch_common_crawl_data(max_records=max_records)
    
    if training_data:
        print(f"ğŸ“š {len(training_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’é–‹å§‹ (ã‚¨ãƒãƒƒã‚¯: {epochs})")
        try:
            model.train_on_texts(training_data, epochs=epochs)
            is_pretrained = True
            print("âœ… äº‹å‰å­¦ç¿’å®Œäº†")
        except Exception as e:
            print(f"âš ï¸ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print("âš ï¸ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")


def get_layered_model(pretrain: bool = True):
    """Layeredãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆäº‹å‰å­¦ç¿’ä»˜ãï¼‰"""
    global layered_ai
    if layered_ai is None and LAYERED_AVAILABLE:
        print("ğŸ”„ Layeredãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        layered_ai = NeuroQuantumAI()
        print("âœ… Layeredãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        
        if pretrain:
            pretrain_model(layered_ai)
    
    return layered_ai


def get_brain_model(pretrain: bool = True):
    """Brainãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆäº‹å‰å­¦ç¿’ä»˜ãï¼‰"""
    global brain_ai
    if brain_ai is None and BRAIN_AVAILABLE:
        print("ğŸ”„ Brainãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        brain_ai = NeuroQuantumBrainAI()
        print("âœ… Brainãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
        
        if pretrain:
            pretrain_model(brain_ai)
    
    return brain_ai


def handler(event: Dict[str, Any]) -> Dict[str, Any]:
    """
    RunPod Serverless ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹:
    {
        "input": {
            "action": "generate",
            "prompt": "ã“ã‚“ã«ã¡ã¯",
            "mode": "layered",
            "max_length": 100,
            "temperature": 0.8,
            "pretrain": true
        }
    }
    """
    try:
        input_data = event.get("input", {})
        action = input_data.get("action", "generate")
        pretrain = input_data.get("pretrain", True)
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        if action == "health":
            return {
                "status": "healthy",
                "layered_available": LAYERED_AVAILABLE,
                "brain_available": BRAIN_AVAILABLE,
                "common_crawl_available": COMMON_CRAWL_AVAILABLE,
                "cuda_available": torch.cuda.is_available(),
                "is_pretrained": is_pretrained
            }
        
        # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
        if action == "generate":
            mode = input_data.get("mode", "layered")
            prompt = input_data.get("prompt", "")
            max_length = input_data.get("max_length", 100)
            temperature = input_data.get("temperature", 0.8)
            top_k = input_data.get("top_k", 50)
            top_p = input_data.get("top_p", 0.9)
            
            if mode == "layered" and LAYERED_AVAILABLE:
                model = get_layered_model(pretrain=pretrain)
                result = model.generate(
                    prompt=prompt,
                    max_length=max_length,
                    temp_min=temperature * 0.8,  # Convert temperature to temp_min/max range
                    temp_max=temperature * 1.2,
                    top_k=top_k,
                    top_p=top_p
                )
                return {
                    "status": "success",
                    "mode": "layered",
                    "prompt": prompt,
                    "generated_text": result,
                    "is_pretrained": is_pretrained
                }
            
            elif mode == "brain" and BRAIN_AVAILABLE:
                model = get_brain_model(pretrain=pretrain)
                result = model.generate(
                    prompt=prompt,
                    max_length=max_length,
                    temperature_min=temperature * 0.8,  # Convert temperature to temperature_min/max range
                    temperature_max=temperature * 1.2
                )
                return {
                    "status": "success",
                    "mode": "brain",
                    "prompt": prompt,
                    "generated_text": result,
                    "is_pretrained": is_pretrained
                }
            
            else:
                return {
                    "status": "error",
                    "error": f"ãƒ¢ãƒ¼ãƒ‰ '{mode}' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"
                }
        
        # è¿½åŠ å­¦ç¿’
        if action == "train":
            mode = input_data.get("mode", "layered")
            training_data = input_data.get("training_data", [])
            epochs = input_data.get("epochs", 10)
            use_common_crawl = input_data.get("use_common_crawl", False)
            max_records = input_data.get("max_records", 50)
            
            # Common Crawlã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            if use_common_crawl:
                cc_data = fetch_common_crawl_data(max_records=max_records)
                training_data.extend(cc_data)
            
            if not training_data:
                return {"status": "error", "error": "training_data ãŒå¿…è¦ã§ã™"}
            
            if mode == "layered" and LAYERED_AVAILABLE:
                model = get_layered_model(pretrain=False)
                model.train_on_texts(training_data, epochs=epochs)
                return {
                    "status": "success",
                    "mode": "layered",
                    "message": f"{len(training_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§{epochs}ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†"
                }
            
            elif mode == "brain" and BRAIN_AVAILABLE:
                model = get_brain_model(pretrain=False)
                model.train_on_texts(training_data, epochs=epochs)
                return {
                    "status": "success",
                    "mode": "brain",
                    "message": f"{len(training_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§{epochs}ã‚¨ãƒãƒƒã‚¯å­¦ç¿’å®Œäº†"
                }
            
            else:
                return {"status": "error", "error": f"ãƒ¢ãƒ¼ãƒ‰ '{mode}' ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"}
        
        return {"status": "error", "error": f"ä¸æ˜ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}"}
    
    except Exception as e:
        return {"status": "error", "error": str(e)}


# RunPod Serverless èµ·å‹•
if __name__ == "__main__":
    print("ğŸš€ NeuroQ RunPod Serverless Handler ã‚’èµ·å‹•ã—ã¾ã™...")
    print(f"   Common Crawl: {'âœ…' if COMMON_CRAWL_AVAILABLE else 'âŒ'}")
    print(f"   Layered: {'âœ…' if LAYERED_AVAILABLE else 'âŒ'}")
    print(f"   Brain: {'âœ…' if BRAIN_AVAILABLE else 'âŒ'}")
    runpod.serverless.start({"handler": handler})
