#!/usr/bin/env python3
"""
RunPod Serverless Handler - æ”¹å–„ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹

ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
"""

import requests
import json
import os
import time

# ========================================
# è¨­å®š
# ========================================
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
ENDPOINT_ID = os.getenv("RUNPOD_ENDPOINT_ID")
RUNPOD_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"

if not RUNPOD_API_KEY or not ENDPOINT_ID:
    print("âš ï¸ ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
    print("   export RUNPOD_API_KEY='your_api_key'")
    print("   export RUNPOD_ENDPOINT_ID='your_endpoint_id'")
    exit(1)


def send_request(input_data: dict, timeout: int = 600) -> dict:
    """RunPodã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {RUNPOD_API_KEY}"
    }
    
    payload = {"input": input_data}
    
    print(f"ğŸ“¤ ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡: {input_data.get('action', 'unknown')}")
    print(f"   ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout}ç§’")
    
    try:
        response = requests.post(
            RUNPOD_URL,
            headers=headers,
            json=payload,
            timeout=timeout
        )
        response.raise_for_status()
        return response.json()
    except requests.exceptions.Timeout:
        return {"error": f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout}ç§’ä»¥å†…ã«å®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ"}
    except requests.exceptions.RequestException as e:
        return {"error": f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}"}


# ========================================
# æ”¹å–„ã•ã‚ŒãŸç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¾‹
# ========================================

def generate_text_optimized(prompt: str, mode: str = "layered") -> dict:
    """
    æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
    
    æ”¹å–„ç‚¹:
    - max_lengthã‚’é©åˆ‡ã«åˆ¶é™ (100-150)
    - repetition_penaltyã‚’å¼·åŒ– (2.0-2.5)
    - temperatureã‚’é©åˆ‡ã«è¨­å®š (0.6-0.8)
    - top_kã¨top_pã‚’èª¿æ•´
    """
    return send_request({
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": 100,  # é©åˆ‡ãªé•·ã•ã«åˆ¶é™
        "temperature": 0.7,  # ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ¸©åº¦
        "top_k": 40,  # Top-K ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        "top_p": 0.9,  # Top-P (Nucleus) ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        "repetition_penalty": 2.5,  # ç¹°ã‚Šè¿”ã—ã‚’å¼·ãæŠ‘åˆ¶
    }, timeout=300)


def generate_with_short_response(prompt: str, mode: str = "layered") -> dict:
    """çŸ­ã„å›ç­”ã‚’ç”Ÿæˆï¼ˆä¼šè©±å½¢å¼å‘ã‘ï¼‰"""
    return send_request({
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": 80,  # çŸ­ã‚ã«è¨­å®š
        "temperature": 0.6,  # å°‘ã—ä½ã‚ã§ä¸€è²«æ€§ã‚’ä¿ã¤
        "top_k": 30,
        "top_p": 0.85,
        "repetition_penalty": 2.5,  # ç¹°ã‚Šè¿”ã—ã‚’å¼·ãæŠ‘åˆ¶
    }, timeout=300)


def generate_with_long_response(prompt: str, mode: str = "layered") -> dict:
    """é•·ã„å›ç­”ã‚’ç”Ÿæˆï¼ˆèª¬æ˜å‘ã‘ï¼‰"""
    return send_request({
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": 150,  # é•·ã‚ã«è¨­å®š
        "temperature": 0.8,  # å°‘ã—é«˜ã‚ã§å¤šæ§˜æ€§ã‚’æŒãŸã›ã‚‹
        "top_k": 50,
        "top_p": 0.95,
        "repetition_penalty": 2.0,  # é•·æ–‡ã®å ´åˆã¯å°‘ã—ç·©ã‚ã‚‹
    }, timeout=300)


def generate_creative(prompt: str, mode: str = "layered") -> dict:
    """å‰µé€ çš„ãªå›ç­”ã‚’ç”Ÿæˆ"""
    return send_request({
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": 120,
        "temperature": 0.9,  # é«˜ã‚ã§å¤šæ§˜æ€§ã‚’æŒãŸã›ã‚‹
        "top_k": 60,
        "top_p": 0.95,
        "repetition_penalty": 2.0,
    }, timeout=300)


def generate_precise(prompt: str, mode: str = "layered") -> dict:
    """æ­£ç¢ºãªå›ç­”ã‚’ç”Ÿæˆï¼ˆäº‹å®Ÿãƒ™ãƒ¼ã‚¹ï¼‰"""
    return send_request({
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": 100,
        "temperature": 0.5,  # ä½ã‚ã§ä¸€è²«æ€§ã‚’ä¿ã¤
        "top_k": 20,
        "top_p": 0.8,
        "repetition_penalty": 2.5,
    }, timeout=300)


# ========================================
# ä½¿ç”¨ä¾‹
# ========================================

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ§ âš›ï¸ ãƒ‹ãƒ¥ãƒ¼ãƒ­Q RunPod - æ”¹å–„ã•ã‚ŒãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹")
    print("=" * 70)
    print()
    
    # ä¾‹1: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    print("1ï¸âƒ£ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
    print("-" * 70)
    result = send_request({"action": "health"}, timeout=30)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    print()
    
    # ä¾‹2: æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”Ÿæˆ
    print("2ï¸âƒ£ æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç”Ÿæˆ")
    print("-" * 70)
    result = generate_text_optimized("ChatGPTã«ã¤ã„ã¦æ•™ãˆã¦", mode="layered")
    
    if "output" in result:
        output = result["output"]
        if "generated" in output:
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {output.get('prompt', '')}")
            print(f"\nç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{output['generated']}")
            print(f"\nèªå½™ã‚µã‚¤ã‚º: {output.get('vocab_size', 'N/A')}")
        elif "error" in output:
            print(f"ã‚¨ãƒ©ãƒ¼: {output['error']}")
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    print()
    
    # ä¾‹3: çŸ­ã„å›ç­”ã‚’ç”Ÿæˆ
    print("3ï¸âƒ£ çŸ­ã„å›ç­”ã‚’ç”Ÿæˆï¼ˆä¼šè©±å½¢å¼ï¼‰")
    print("-" * 70)
    result = generate_with_short_response("é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ", mode="layered")
    
    if "output" in result and "generated" in result["output"]:
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {result['output'].get('prompt', '')}")
        print(f"\nç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{result['output']['generated']}")
    print()
    
    # ä¾‹4: é•·ã„å›ç­”ã‚’ç”Ÿæˆ
    print("4ï¸âƒ£ é•·ã„å›ç­”ã‚’ç”Ÿæˆï¼ˆèª¬æ˜å½¢å¼ï¼‰")
    print("-" * 70)
    result = generate_with_long_response("ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä»•çµ„ã¿ã‚’èª¬æ˜ã—ã¦ãã ã•ã„", mode="layered")
    
    if "output" in result and "generated" in result["output"]:
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {result['output'].get('prompt', '')}")
        print(f"\nç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{result['output']['generated']}")
    print()
    
    # ä¾‹5: è¤‡æ•°ã®è³ªå•ã‚’è©¦ã™
    print("5ï¸âƒ£ è¤‡æ•°ã®è³ªå•ã‚’è©¦ã™")
    print("-" * 70)
    
    questions = [
        "ã“ã‚“ã«ã¡ã¯",
        "ã‚ãªãŸã¯èª°ã§ã™ã‹",
        "AIã¨ã¯ä½•ã§ã™ã‹",
        "æ©Ÿæ¢°å­¦ç¿’ã«ã¤ã„ã¦æ•™ãˆã¦",
    ]
    
    for i, question in enumerate(questions, 1):
        print(f"\nè³ªå• {i}: {question}")
        print("-" * 50)
        
        result = generate_text_optimized(question, mode="layered")
        
        if "output" in result and "generated" in result["output"]:
            generated = result["output"]["generated"]
            # æœ€åˆã®200æ–‡å­—ã ã‘è¡¨ç¤ºï¼ˆé•·ã™ãã‚‹å ´åˆï¼‰
            if len(generated) > 200:
                print(f"ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆï¼ˆæœ€åˆã®200æ–‡å­—ï¼‰:\n{generated[:200]}...")
            else:
                print(f"ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{generated}")
        
        time.sleep(1)  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’ç©ºã‘ã‚‹
    
    print("\n" + "=" * 70)
    print("âœ… å®Œäº†")
    print("=" * 70)

