{
  "説明": "改善された学習を含むリクエスト例 - 生成テキストの品質向上のため",
  
  "改善のポイント": {
    "学習データ": "より多くのデータレコード（300-500）",
    "エポック数": "より多くのエポック（30-50）",
    "生成パラメータ": "特殊トークンの生成を抑制",
    "モデルパラメータ": "より大きなモデルサイズ"
  },

  "example_1_短時間改善版": {
    "説明": "既存設定を少し改善したバージョン（学習時間: 約2-5分）",
    "input": {
      "action": "generate",
      "mode": "layered",
      "prompt": "ChatGPTについて教えて",
      "max_length": 80,
      "temperature": 0.6,
      "top_k": 30,
      "top_p": 0.85,
      "repetition_penalty": 3.0,
      "train_before_generate": true,
      "data_sources": ["huggingface"],
      "common_crawl_config": {
        "max_records": 300
      },
      "epochs": 30,
      "batch_size": 16,
      "learning_rate": 0.0005,
      "seq_length": 64
    }
  },

  "example_2_標準改善版": {
    "説明": "バランスの取れた改善版（学習時間: 約5-10分）",
    "input": {
      "action": "generate",
      "mode": "layered",
      "prompt": "ChatGPTについて教えて",
      "max_length": 100,
      "temperature": 0.6,
      "top_k": 30,
      "top_p": 0.85,
      "repetition_penalty": 3.0,
      "train_before_generate": true,
      "data_sources": ["huggingface"],
      "common_crawl_config": {
        "max_records": 500
      },
      "epochs": 50,
      "batch_size": 32,
      "learning_rate": 0.0001,
      "seq_length": 128,
      "embed_dim": 256,
      "hidden_dim": 512,
      "num_heads": 8,
      "num_layers": 4
    }
  },

  "example_3_高品質版": {
    "説明": "最高品質を目指す設定（学習時間: 約15-30分）",
    "input": {
      "action": "generate",
      "mode": "layered",
      "prompt": "ChatGPTについて教えて",
      "max_length": 100,
      "temperature": 0.6,
      "top_k": 30,
      "top_p": 0.85,
      "repetition_penalty": 3.0,
      "train_before_generate": true,
      "data_sources": ["huggingface"],
      "common_crawl_config": {
        "max_records": 1000
      },
      "epochs": 100,
      "batch_size": 64,
      "learning_rate": 0.00005,
      "seq_length": 256,
      "embed_dim": 512,
      "hidden_dim": 1024,
      "num_heads": 16,
      "num_layers": 6
    }
  },

  "example_4_テスト用（最小設定）": {
    "説明": "最も短時間でテストする場合（学習時間: 約1-2分）",
    "input": {
      "action": "generate",
      "mode": "layered",
      "prompt": "こんにちは",
      "max_length": 50,
      "temperature": 0.6,
      "top_k": 30,
      "top_p": 0.85,
      "repetition_penalty": 3.0,
      "train_before_generate": true,
      "data_sources": ["huggingface"],
      "common_crawl_config": {
        "max_records": 150
      },
      "epochs": 20,
      "batch_size": 16,
      "learning_rate": 0.001,
      "seq_length": 64
    }
  },

  "パラメータ説明_改善版": {
    "学習パラメータ": {
      "max_records": "300-1000推奨（100は少なすぎる）",
      "epochs": "30-100推奨（20は少なすぎる）",
      "batch_size": "32-64推奨（より安定した学習）",
      "learning_rate": "0.00005-0.0005推奨（より細かい調整）",
      "seq_length": "128-256推奨（より長いコンテキスト）"
    },
    "生成パラメータ_改善": {
      "temperature": "0.6推奨（0.7より低くして一貫性を高める）",
      "top_k": "30推奨（40より低くして特殊トークンを抑制）",
      "top_p": "0.85推奨（0.9より低くして多様性を抑える）",
      "repetition_penalty": "3.0推奨（2.5より高くして繰り返しと特殊トークンを抑制）"
    },
    "モデルパラメータ_改善": {
      "embed_dim": "256-512推奨（より大きな埋め込み空間）",
      "hidden_dim": "512-1024推奨（より大きな隠れ層）",
      "num_heads": "8-16推奨（より多くのアテンションヘッド）",
      "num_layers": "4-6推奨（より深いネットワーク）"
    }
  },

  "現在の問題と改善策": {
    "問題": [
      "特殊トークン（PARAGRAPH_ARTICLE、SECTIONなど）が生成される",
      "意味のない文字列が生成される",
      "日本語の文法が崩れている"
    ],
    "改善策": [
      "学習データを増やす（max_records: 100 → 300-500）",
      "エポック数を増やす（epochs: 20 → 30-50）",
      "生成パラメータを調整（repetition_penalty: 2.5 → 3.0、temperature: 0.7 → 0.6）",
      "より大きなモデルサイズを使用",
      "より長いシーケンス長を使用（seq_length: 64 → 128-256）"
    ]
  }
}

