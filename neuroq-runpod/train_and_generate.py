#!/usr/bin/env python3
"""
RunPod Serverless Handler - å­¦ç¿’ã—ã¦ã‹ã‚‰ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

train_before_generateãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’â†’ç”Ÿæˆã‚’å®Ÿè¡Œ
"""

import requests
import json
import os
import time
from typing import Optional, Dict, Any

# ========================================
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
# ========================================
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
ENDPOINT_ID = os.getenv("RUNPOD_ENDPOINT_ID")

if not RUNPOD_API_KEY or not ENDPOINT_ID:
    print("=" * 60)
    print("âš ï¸ ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    print("=" * 60)
    exit(1)

RUNPOD_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"
STATUS_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/status"


def send_and_wait(input_data: dict, timeout: int = 3600) -> dict:
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã¦å®Œäº†ã‚’å¾…ã¤"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {RUNPOD_API_KEY}"
    }
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
    print("ğŸ“¤ RunPodã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
    response = requests.post(
        RUNPOD_URL,
        headers=headers,
        json={"input": input_data},
        timeout=30
    )
    response.raise_for_status()
    job_data = response.json()
    
    job_id = job_data.get("id")
    if not job_id:
        return {"error": "ã‚¸ãƒ§ãƒ–IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}
    
    print(f"âœ… ã‚¸ãƒ§ãƒ–ID: {job_id}")
    print("â³ å­¦ç¿’ã¨ç”Ÿæˆã®å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ãƒªãƒ³ã‚°
    status_headers = {"Authorization": f"Bearer {RUNPOD_API_KEY}"}
    status_url = f"{STATUS_URL}/{job_id}"
    start_time = time.time()
    last_status = None
    
    while time.time() - start_time < timeout:
        try:
            status_response = requests.get(status_url, headers=status_headers, timeout=30)
            status_response.raise_for_status()
            result = status_response.json()
            
            current_status = result.get("status", "UNKNOWN")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¤‰ã‚ã£ãŸã‚‰è¡¨ç¤º
            if current_status != last_status:
                elapsed = int(time.time() - start_time)
                print(f"   ğŸ“Š {current_status} ({elapsed}ç§’)")
                last_status = current_status
            
            if current_status == "COMPLETED":
                output = result.get("output", {})
                if "error" in output:
                    return {"error": output["error"]}
                return {"output": output, "status": "completed"}
            
            elif current_status == "FAILED":
                output = result.get("output", {})
                error_msg = output.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼") if isinstance(output, dict) else str(output)
                print(f"\n   âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
                print(f"      ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error_msg}")
                print(f"\n   å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return {"error": f"å¤±æ•—: {error_msg}", "status": "failed"}
            
            # ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”
            time.sleep(3)
            
        except requests.exceptions.RequestException as e:
            print(f"   âš ï¸ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(5)
    
    return {"error": f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout}ç§’ä»¥å†…ã«å®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ", "status": "timeout"}


def train_and_generate(
    prompt: str,
    mode: str = "layered",
    epochs: int = 20,
    batch_size: int = 16,
    learning_rate: float = 0.001,
    seq_length: int = 64,
    max_records: int = 100,
    data_sources: list = ["huggingface"],
    max_length: int = 100,
    temperature: float = 0.7,
    top_k: int = 40,
    top_p: float = 0.9,
    repetition_penalty: float = 2.0,
    **model_kwargs
) -> Dict[str, Any]:
    """
    å­¦ç¿’ã—ã¦ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆtrain_before_generateãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨ï¼‰
    """
    payload = {
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": max_length,
        "temperature": temperature,
        "top_k": top_k,
        "top_p": top_p,
        "repetition_penalty": repetition_penalty,
        "train_before_generate": True,
        "epochs": epochs,
        "batch_size": batch_size,
        "learning_rate": learning_rate,
        "seq_length": seq_length,
        "data_sources": data_sources,
        "common_crawl_config": {"max_records": max_records},
        **model_kwargs
    }
    
    timeout = 3600  # 1æ™‚é–“
    return send_and_wait(payload, timeout=timeout)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ğŸ§ âš›ï¸ ãƒ‹ãƒ¥ãƒ¼ãƒ­Q RunPod - å­¦ç¿’ã—ã¦ã‹ã‚‰ç”Ÿæˆ")
    print("=" * 60)
    print()
    
    # å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ”¹å–„ç‰ˆ - ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã‚’æŠ‘åˆ¶ï¼‰
    mode = "layered"
    epochs = 30  # 30ã‚¨ãƒãƒƒã‚¯ã«å¢—åŠ ï¼ˆã‚ˆã‚Šè‰¯ã„å­¦ç¿’ã®ãŸã‚ï¼‰
    batch_size = 16
    learning_rate = 0.0005  # ã‚ˆã‚Šç´°ã‹ã„å­¦ç¿’ç‡
    max_records = 300  # ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ï¼ˆ100â†’300ï¼‰
    
    # ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ”¹å–„ç‰ˆ - ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ‘åˆ¶ï¼‰
    prompt = "ChatGPTã«ã¤ã„ã¦æ•™ãˆã¦"
    max_length = 80
    temperature = 0.6  # 0.7â†’0.6ã«ä¸‹ã’ã¦ä¸€è²«æ€§ã‚’é«˜ã‚ã‚‹
    top_k = 30  # 40â†’30ã«ä¸‹ã’ã¦ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ‘åˆ¶
    top_p = 0.85  # 0.9â†’0.85ã«ä¸‹ã’ã¦å¤šæ§˜æ€§ã‚’æŠ‘ãˆã‚‹
    repetition_penalty = 3.0  # 2.5â†’3.0ã«ä¸Šã’ã¦ç¹°ã‚Šè¿”ã—ã¨ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¼·ãæŠ‘åˆ¶
    
    print(f"ğŸ“‹ å­¦ç¿’è¨­å®š:")
    print(f"   ãƒ¢ãƒ¼ãƒ‰: {mode}")
    print(f"   ã‚¨ãƒãƒƒã‚¯æ•°: {epochs}")
    print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"   å­¦ç¿’ç‡: {learning_rate}")
    print(f"   æœ€å¤§ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {max_records}")
    print()
    print(f"ğŸ“ ç”Ÿæˆè¨­å®š:")
    print(f"   ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print(f"   æœ€å¤§é•·: {max_length}")
    print(f"   æ¸©åº¦: {temperature}")
    print(f"   Top-K: {top_k}")
    print(f"   Top-P: {top_p}")
    print(f"   ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£: {repetition_penalty}")
    print()
    
    # å­¦ç¿’â†’ç”Ÿæˆå®Ÿè¡Œ
    print("ğŸš€ å­¦ç¿’ã¨ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")
    print("   â³ ã“ã®å‡¦ç†ã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")
    print()
    
    result = train_and_generate(
        prompt=prompt,
        mode=mode,
        epochs=epochs,
        batch_size=batch_size,
        learning_rate=learning_rate,
        max_records=max_records,
        max_length=max_length,
        temperature=temperature,
        top_k=top_k,
        top_p=top_p,
        repetition_penalty=repetition_penalty
    )
    
    print()
    print("=" * 60)
    
    if "error" in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    elif "output" in result:
        output = result["output"]
        
        # ç”Ÿæˆçµæœã‚’è¡¨ç¤º
        if "generated" in output:
            print(f"âœ… ç”Ÿæˆå®Œäº†ï¼")
            print()
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {output.get('prompt', prompt)}")
            print()
            print(f"ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:")
            print(f"{output['generated']}")
        else:
            print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("=" * 60)


if __name__ == "__main__":
    main()

