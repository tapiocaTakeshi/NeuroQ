#!/usr/bin/env python3
"""
RunPod Serverless Handler - æ”¹å–„ç‰ˆå­¦ç¿’â†’ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
"""

import requests
import json
import os
import time
from typing import Optional, Dict, Any

# ========================================
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
# ========================================
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
ENDPOINT_ID = os.getenv("RUNPOD_ENDPOINT_ID")

if not RUNPOD_API_KEY or not ENDPOINT_ID:
    print("=" * 60)
    print("âš ï¸ ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    print("=" * 60)
    exit(1)

RUNPOD_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"
STATUS_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/status"


def send_and_wait(input_data: dict, timeout: int = 3600) -> dict:
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ã—ã¦å®Œäº†ã‚’å¾…ã¤"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {RUNPOD_API_KEY}"
    }
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
    print("ğŸ“¤ RunPodã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
    response = requests.post(
        RUNPOD_URL,
        headers=headers,
        json={"input": input_data},
        timeout=30
    )
    response.raise_for_status()
    job_data = response.json()
    
    job_id = job_data.get("id")
    if not job_id:
        return {"error": "ã‚¸ãƒ§ãƒ–IDãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"}
    
    print(f"âœ… ã‚¸ãƒ§ãƒ–ID: {job_id}")
    print("â³ å­¦ç¿’ã¨ç”Ÿæˆã®å®Œäº†ã‚’å¾…ã£ã¦ã„ã¾ã™...")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ãƒªãƒ³ã‚°
    status_headers = {"Authorization": f"Bearer {RUNPOD_API_KEY}"}
    status_url = f"{STATUS_URL}/{job_id}"
    start_time = time.time()
    last_status = None
    
    while time.time() - start_time < timeout:
        try:
            status_response = requests.get(status_url, headers=status_headers, timeout=30)
            status_response.raise_for_status()
            result = status_response.json()
            
            current_status = result.get("status", "UNKNOWN")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒå¤‰ã‚ã£ãŸã‚‰è¡¨ç¤º
            if current_status != last_status:
                elapsed = int(time.time() - start_time)
                print(f"   ğŸ“Š {current_status} ({elapsed}ç§’)")
                last_status = current_status
            
            if current_status == "COMPLETED":
                output = result.get("output", {})
                if "error" in output:
                    return {"error": output["error"]}
                return {"output": output, "status": "completed"}
            
            elif current_status == "FAILED":
                output = result.get("output", {})
                error_msg = output.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼") if isinstance(output, dict) else str(output)
                print(f"\n   âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°:")
                print(f"      ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error_msg}")
                print(f"\n   å®Œå…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹:")
                print(json.dumps(result, indent=2, ensure_ascii=False))
                return {"error": f"å¤±æ•—: {error_msg}", "status": "failed"}
            
            # ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”
            time.sleep(3)
            
        except requests.exceptions.RequestException as e:
            print(f"   âš ï¸ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(5)
    
    return {"error": f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {timeout}ç§’ä»¥å†…ã«å®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ", "status": "timeout"}


def train_and_generate_improved(
    prompt: str,
    mode: str = "layered",
    preset: str = "short",  # "short", "standard", "high_quality"
    **custom_params
) -> Dict[str, Any]:
    """
    æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’â†’ç”Ÿæˆã‚’å®Ÿè¡Œ
    
    Args:
        prompt: ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        mode: "layered" ã¾ãŸã¯ "brain"
        preset: ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š ("short", "standard", "high_quality")
        **custom_params: ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆã‚’ä¸Šæ›¸ãï¼‰
    """
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆè¨­å®š
    presets = {
        "short": {
            "max_records": 300,
            "epochs": 30,
            "batch_size": 16,
            "learning_rate": 0.0005,
            "seq_length": 64,
            "max_length": 80,
            "temperature": 0.6,
            "top_k": 30,
            "top_p": 0.85,
            "repetition_penalty": 3.0
        },
        "standard": {
            "max_records": 500,
            "epochs": 50,
            "batch_size": 32,
            "learning_rate": 0.0001,
            "seq_length": 128,
            "max_length": 100,
            "temperature": 0.6,
            "top_k": 30,
            "top_p": 0.85,
            "repetition_penalty": 3.0,
            "embed_dim": 256,
            "hidden_dim": 512,
            "num_heads": 8,
            "num_layers": 4
        },
        "high_quality": {
            "max_records": 1000,
            "epochs": 100,
            "batch_size": 64,
            "learning_rate": 0.00005,
            "seq_length": 256,
            "max_length": 100,
            "temperature": 0.6,
            "top_k": 30,
            "top_p": 0.85,
            "repetition_penalty": 3.0,
            "embed_dim": 512,
            "hidden_dim": 1024,
            "num_heads": 16,
            "num_layers": 6
        }
    }
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’å–å¾—
    params = presets.get(preset, presets["short"]).copy()
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ä¸Šæ›¸ã
    params.update(custom_params)
    
    # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ä½œæˆ
    payload = {
        "action": "generate",
        "mode": mode,
        "prompt": prompt,
        "max_length": params.pop("max_length"),
        "temperature": params.pop("temperature"),
        "top_k": params.pop("top_k"),
        "top_p": params.pop("top_p"),
        "repetition_penalty": params.pop("repetition_penalty"),
        "train_before_generate": True,
        "epochs": params.pop("epochs"),
        "batch_size": params.pop("batch_size"),
        "learning_rate": params.pop("learning_rate"),
        "seq_length": params.pop("seq_length"),
        "data_sources": ["huggingface"],
        "common_crawl_config": {
            "max_records": params.pop("max_records")
        },
        **params  # æ®‹ã‚Šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã©ï¼‰
    }
    
    timeout = 3600 if preset == "high_quality" else 1800 if preset == "standard" else 600
    return send_and_wait(payload, timeout=timeout)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=" * 60)
    print("ğŸ§ âš›ï¸ ãƒ‹ãƒ¥ãƒ¼ãƒ­Q RunPod - æ”¹å–„ç‰ˆå­¦ç¿’â†’ç”Ÿæˆ")
    print("=" * 60)
    print()
    
    # æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    mode = "layered"
    preset = "short"  # "short", "standard", "high_quality"
    prompt = "ChatGPTã«ã¤ã„ã¦æ•™ãˆã¦"
    
    print(f"ğŸ“‹ è¨­å®š:")
    print(f"   ãƒ¢ãƒ¼ãƒ‰: {mode}")
    print(f"   ãƒ—ãƒªã‚»ãƒƒãƒˆ: {preset}")
    print(f"   ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
    print()
    
    if preset == "short":
        print("ğŸ“Š å­¦ç¿’è¨­å®š (çŸ­æ™‚é–“æ”¹å–„ç‰ˆ):")
        print("   ã‚¨ãƒãƒƒã‚¯æ•°: 30")
        print("   ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: 300")
        print("   å­¦ç¿’ç‡: 0.0005")
        print()
        print("ğŸ“ ç”Ÿæˆè¨­å®š (æ”¹å–„ç‰ˆ):")
        print("   æ¸©åº¦: 0.6 (ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ‘åˆ¶)")
        print("   Top-K: 30 (ã‚ˆã‚Šä¿å®ˆçš„)")
        print("   Top-P: 0.85 (å¤šæ§˜æ€§ã‚’æŠ‘ãˆã‚‹)")
        print("   ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£: 3.0 (ã‚ˆã‚Šå¼·åŠ›)")
    elif preset == "standard":
        print("ğŸ“Š å­¦ç¿’è¨­å®š (æ¨™æº–æ”¹å–„ç‰ˆ):")
        print("   ã‚¨ãƒãƒƒã‚¯æ•°: 50")
        print("   ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: 500")
        print("   å­¦ç¿’ç‡: 0.0001")
        print("   ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«")
        print()
        print("ğŸ“ ç”Ÿæˆè¨­å®š (æ”¹å–„ç‰ˆ):")
        print("   æ¸©åº¦: 0.6")
        print("   Top-K: 30")
        print("   ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£: 3.0")
    elif preset == "high_quality":
        print("ğŸ“Š å­¦ç¿’è¨­å®š (é«˜å“è³ªç‰ˆ):")
        print("   ã‚¨ãƒãƒƒã‚¯æ•°: 100")
        print("   ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: 1000")
        print("   å­¦ç¿’ç‡: 0.00005")
        print("   ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: æœ€å¤§")
        print()
        print("ğŸ“ ç”Ÿæˆè¨­å®š (æ”¹å–„ç‰ˆ):")
        print("   æ¸©åº¦: 0.6")
        print("   Top-K: 30")
        print("   ç¹°ã‚Šè¿”ã—ãƒšãƒŠãƒ«ãƒ†ã‚£: 3.0")
    
    print()
    print("ğŸš€ å­¦ç¿’ã¨ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")
    print("   â³ ã“ã®å‡¦ç†ã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")
    print()
    
    result = train_and_generate_improved(
        prompt=prompt,
        mode=mode,
        preset=preset
    )
    
    print()
    print("=" * 60)
    
    if "error" in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    elif "output" in result:
        output = result["output"]
        
        # ç”Ÿæˆçµæœã‚’è¡¨ç¤º
        if "generated" in output:
            print(f"âœ… ç”Ÿæˆå®Œäº†ï¼")
            print()
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {output.get('prompt', prompt)}")
            print()
            print(f"ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:")
            print(f"{output['generated']}")
            print()
            
            # ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®æ¤œå‡º
            special_tokens = ["PARAGRAPH", "SECTION", "START", "NEWLINE", "ARTICLE"]
            found_tokens = [token for token in special_tokens if token in output['generated']]
            if found_tokens:
                print(f"âš ï¸ æ³¨æ„: ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {', '.join(found_tokens)}")
                print(f"   ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚¨ãƒãƒƒã‚¯æ•°ã§å­¦ç¿’ã™ã‚‹ã¨æ”¹å–„ã•ã‚Œã¾ã™ã€‚")
        else:
            print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("=" * 60)


if __name__ == "__main__":
    main()

