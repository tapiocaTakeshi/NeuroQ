#!/usr/bin/env python3
"""
RunPod Serverless Handler - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆä¾‹

ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹
"""

import requests
import json
import os

# ========================================
# è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
# ========================================
RUNPOD_API_KEY = os.getenv("RUNPOD_API_KEY")
ENDPOINT_ID = os.getenv("RUNPOD_ENDPOINT_ID")
RUNPOD_URL = f"https://api.runpod.ai/v2/{ENDPOINT_ID}/run"

if not RUNPOD_API_KEY or not ENDPOINT_ID:
    print("âš ï¸ ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„:")
    print("   export RUNPOD_API_KEY='your_api_key'")
    print("   export RUNPOD_ENDPOINT_ID='your_endpoint_id'")
    exit(1)


# ========================================
# ã‚·ãƒ³ãƒ—ãƒ«ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆé–¢æ•°
# ========================================

def send_request(input_data: dict) -> dict:
    """RunPodã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {RUNPOD_API_KEY}"
    }
    
    payload = {"input": input_data}
    
    response = requests.post(RUNPOD_URL, headers=headers, json=payload, timeout=600)
    response.raise_for_status()
    return response.json()


# ========================================
# ä½¿ç”¨ä¾‹
# ========================================

if __name__ == "__main__":
    print("ğŸ§ âš›ï¸ ãƒ‹ãƒ¥ãƒ¼ãƒ­Q RunPod - ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ\n")
    
    # ä¾‹1: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    print("1ï¸âƒ£ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯")
    print("-" * 50)
    result = send_request({"action": "health"})
    print(json.dumps(result, indent=2, ensure_ascii=False))
    print()
    
    # ä¾‹2: ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼‰
    print("2ï¸âƒ£ ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ")
    print("-" * 50)
    result = send_request({
        "action": "generate",
        "mode": "layered",
        "prompt": "ChatGPTã«ã¤ã„ã¦æ•™ãˆã¦",
        "max_length": 80,  # çŸ­ã‚ã«è¨­å®šã—ã¦ç¹°ã‚Šè¿”ã—ã‚’é˜²ã
        "temperature": 0.7,
        "top_k": 40,
        "top_p": 0.9,
        "repetition_penalty": 2.5  # ç¹°ã‚Šè¿”ã—ã‚’å¼·ãæŠ‘åˆ¶
    })
    
    if "generated" in result.get("output", {}):
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {result['output'].get('prompt', '')}")
        print(f"\nç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{result['output']['generated']}")
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    print()
    
    # ä¾‹3: å­¦ç¿’ã—ã¦ã‹ã‚‰ç”Ÿæˆ
    print("3ï¸âƒ£ å­¦ç¿’ã—ã¦ã‹ã‚‰ç”Ÿæˆ")
    print("-" * 50)
    print("âš ï¸ ã“ã‚Œã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼ˆæ•°åˆ†ã€œæ•°ååˆ†ï¼‰")
    print()
    
    result = send_request({
        "action": "generate",
        "mode": "layered",
        "prompt": "é‡å­ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "max_length": 150,
        "temperature": 0.7,
        "repetition_penalty": 2.0,
        "train_before_generate": True,
        "data_sources": ["huggingface"],
        "max_records": 50,  # å°‘ãªã‚ã«è¨­å®š
        "epochs": 10  # å°‘ãªã‚ã«è¨­å®š
    })
    
    if "generated" in result.get("output", {}):
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {result['output'].get('prompt', '')}")
        print(f"\nç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆ:\n{result['output']['generated']}")
    else:
        print(json.dumps(result, indent=2, ensure_ascii=False))

